[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Warren Kennedy",
    "section": "",
    "text": "Warren Kennedy is an Operations Analyst at Midland Credit Management, an Encore Capital Group subsidiary. When not innovating on data platforms, Warren enjoys watching sports, walking his dogs, and overpaying for popcorn at movie theatres.\n\nEducation\nUC San Diego Rady School of Management | San Diego, CA\n\nMaster of Science in Business Analytics | August 2023 - December 2024\nBachelor of Arts in Economics | September 2021 - June 2023\n\n\n\nExperience\nMidland Credit Management | Operations Analyst | August 2023 - Present"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Warren Kennedy’s Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Poisson Regression Examples\n\n\n\n\n\n\nYour Name\n\n\nMay 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\n\n\nWarren Kennedy\n\n\nMay 3, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Homework 1",
    "section": "",
    "text": "I like to plot data\n\n\nI also analyze data"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Homework 1",
    "section": "",
    "text": "I also analyze data"
  },
  {
    "objectID": "index.html#sub-header",
    "href": "index.html#sub-header",
    "title": "Warren Kennedy",
    "section": "Sub-Header",
    "text": "Sub-Header"
  },
  {
    "objectID": "projects/project1/hw1_questions.html",
    "href": "projects/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment tests a variety of hypotheses, including whether matching donations increases the likelihood of a donation, whether the size of the match matters, and whether the size of the donation is affected by the match. To accomplish this, the authors used a variety of treatments, varying the price ratios for the match, the maximum matching grant amount, and the individual-specific ask amount. The treatments were letters used to solicit donations for a liberal politically motivated group that were sent to all 50 states. To control for spatial heterogeneity, the authors made sure that the treatment and control groups were balanced across states using demographic data, state and county election data, and data on the organization’s activity level within each state. Ultimately, the authors find that matching donations increases the likelihood of a donation, however, they also find that the size of the match does not matter, and that the size of the donation is not affected by the match.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#introduction",
    "href": "projects/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment tests a variety of hypotheses, including whether matching donations increases the likelihood of a donation, whether the size of the match matters, and whether the size of the donation is affected by the match. To accomplish this, the authors used a variety of treatments, varying the price ratios for the match, the maximum matching grant amount, and the individual-specific ask amount. The treatments were letters used to solicit donations for a liberal politically motivated group that were sent to all 50 states. To control for spatial heterogeneity, the authors made sure that the treatment and control groups were balanced across states using demographic data, state and county election data, and data on the organization’s activity level within each state. Ultimately, the authors find that matching donations increases the likelihood of a donation, however, they also find that the size of the match does not matter, and that the size of the donation is not affected by the match.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#data",
    "href": "projects/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data The data used for this experiment has assigned roughly 2/3 of the individuals to the treatment group while assigning the remaining 1/3 of participants to be receive the standard mailing in the control group. Within the treatment group, we see that the different treatment features are evenly distributed across the treatment group participants\n\n# read the data \nlibrary(haven)\ndata &lt;- read_dta(\"/home/jovyan/My_Quarto_Website/projects/project1/karlan_list_2007.dta\")\n\n# summarize treatment/control split\ntreatment_perc &lt;- mean(data$treatment)\ncontrol_perc &lt;-mean(data$control)\n\n# Print the result\nprint(treatment_perc)\n\n[1] 0.6668131\n\nprint(control_perc)\n\n[1] 0.3331869\n\n\n\n# Create tables to show the distributions of the treatment features\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nratio_counts &lt;- data %&gt;%\n  count(ratio) %&gt;%\n  mutate(percentage = round(n / sum(n) * 100,2))\n\nsize_counts &lt;- data %&gt;%\n  count(size) %&gt;%\n  mutate(percentage = round(n / sum(n) * 100,2))\n\nask_counts &lt;- data %&gt;%\n  count(ask) %&gt;%\n  mutate(percentage = round(n / sum(n) * 100,2))\n\n# Print the result\nprint(ratio_counts)\n\n# A tibble: 4 × 3\n  ratio           n percentage\n  &lt;dbl+lbl&gt;   &lt;int&gt;      &lt;dbl&gt;\n1 0 [Control] 16687       33.3\n2 1           11133       22.2\n3 2           11134       22.2\n4 3           11129       22.2\n\nprint(ask_counts)\n\n# A tibble: 4 × 3\n  ask             n percentage\n  &lt;dbl+lbl&gt;   &lt;int&gt;      &lt;dbl&gt;\n1 0 [Control] 16687       33.3\n2 1 [1x]      11134       22.2\n3 2 [1.25x]   11133       22.2\n4 3 [1.50x]   11129       22.2\n\nprint(size_counts)\n\n# A tibble: 5 × 3\n  size             n percentage\n  &lt;dbl+lbl&gt;    &lt;int&gt;      &lt;dbl&gt;\n1 0 [Control]  16687       33.3\n2 1 [$25,000]   8350       16.7\n3 2 [$50,000]   8345       16.7\n4 3 [$100,000]  8350       16.7\n5 4 [Unstated]  8351       16.7\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper).\nWe test for a difference in means using both the t-test method and separately the linear regression method. In this case, we use both methods to confirm what we are seeing, however, both methods will ultimately produce the same result. Comparing the means of both the couple and pwhite variables respectively, we see that there is no statistically significant difference between the observations in the treatment and control groups. We tested this hypothesis for each variable at a 95% confidence level. These results give us the confidence to conclude that we do not have the statistical evidence to reject the null hypothesis that there is no difference in the means between the two groups.\n\nComparing Means for couple\n\n#split data into treatment and control\ncontrol_df &lt;- data[data$treatment == 0, ]\ntreatment_df &lt;- data[data$treatment == 1, ]\n\n# create data for ttest\nmean_control &lt;- mean(control_df$couple, na.rm = TRUE)\nsd_control &lt;- sd(control_df$couple, na.rm = TRUE)\nN_control &lt;- length(control_df$couple)\n\nmean_treatment &lt;- mean(treatment_df$couple, na.rm = TRUE)\nsd_treatment &lt;- sd(treatment_df$couple, na.rm = TRUE)\nN_treatment &lt;- length(treatment_df$couple)\n  \n# calculate tstat\nt_stat &lt;- (mean_control - mean_treatment) / sqrt((sd_control^2 / N_control) + (sd_treatment^2 / N_treatment))\nprint(t_stat)\n\n[1] 0.5888429\n\n\n\ncouple_lm &lt;- lm(couple~treatment, data=data)\nsummary(couple_lm)\n\n\nCall:\nlm(formula = couple ~ treatment, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.09297 -0.09297 -0.09136 -0.09136  0.90864 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.092975   0.002261  41.124   &lt;2e-16 ***\ntreatment   -0.001617   0.002770  -0.584    0.559    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2889 on 48933 degrees of freedom\n  (1148 observations deleted due to missingness)\nMultiple R-squared:  6.965e-06, Adjusted R-squared:  -1.347e-05 \nF-statistic: 0.3408 on 1 and 48933 DF,  p-value: 0.5594\n\n\n\n\nComparing Means for pwhite\n\n#split data into treatment and control\ncontrol_df &lt;- data[data$treatment == 0, ]\ntreatment_df &lt;- data[data$treatment == 1, ]\n\n# create data for ttest\nmean_control &lt;- mean(control_df$pwhite, na.rm = TRUE)\nsd_control &lt;- sd(control_df$pwhite, na.rm = TRUE)\nN_control &lt;- length(control_df$pwhite)\n\nmean_treatment &lt;- mean(treatment_df$pwhite, na.rm = TRUE)\nsd_treatment &lt;- sd(treatment_df$pwhite, na.rm = TRUE)\nN_treatment &lt;- length(treatment_df$pwhite)\n  \n# calculate tstat\nt_stat &lt;- (mean_control - mean_treatment) / sqrt((sd_control^2 / N_control) + (sd_treatment^2 / N_treatment))\nprint(t_stat)\n\n[1] 0.570052\n\n\n\n\nLinear Regression for pwhite\n\npwhite_lm &lt;- lm(pwhite~treatment, data=data)\nsummary(pwhite_lm)\n\n\nCall:\nlm(formula = pwhite ~ treatment, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.81079 -0.06378  0.05300  0.11939  0.18070 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.8202078  0.0013309  616.28   &lt;2e-16 ***\ntreatment   -0.0009128  0.0016292   -0.56    0.575    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1686 on 48215 degrees of freedom\n  (1866 observations deleted due to missingness)\nMultiple R-squared:  6.51e-06,  Adjusted R-squared:  -1.423e-05 \nF-statistic: 0.3139 on 1 and 48215 DF,  p-value: 0.5753"
  },
  {
    "objectID": "projects/project1/hw1_questions.html#experimental-results",
    "href": "projects/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\nUsing a barplot to visually represen the outcome, we first observe the proportion of people who donated using one bar for treatment and one bar for control. Based on the bar plot below, there is a clear difference in the outcome: the treatement group has a higher proportion of people who donated than the control group. The barplot gives us reason to believe that the treatment may have a causal impact on the outcome of giving. Next, we test this hypothesis using statistical methods.\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Calculating proportions\ndonation_summary &lt;- data %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(proportion_donated = mean(gave))\n\n# Ensure 'treatment' is a factor\ndonation_summary$treatment &lt;- as.factor(donation_summary$treatment)\n\n# Plotting the proportions\nggplot(donation_summary, aes(x = treatment, y = proportion_donated, fill = treatment)) +\n  geom_col() +  \n  scale_fill_manual(values = c(\"blue\", \"red\")) + \n  labs(title = \"Proportion of People Who Donated by Treatment Status\",\n       x = \"Treatment Status\",\n       y = \"Proportion that Donated\") +\n  theme_minimal()  \n\n\n\n\n\n\n\n\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\nWe can test our hypothesis by using a t-test to compare the proportions observed between the treatment and control groups. As we have done before, we will confirm the results from our t-test using a bivariate linear regression to demonstrate the same finding.\nThe hypothesis we seek to test is whether or not the proportion of people who gave is the same in both the treatment and the control groups. The result from our t-test is that the treatment group is substantially different from the control group. A large t-stat(t-stat &gt; 2) tells us that we have evidence to suggest that the groups differ and in our case, the t-stat is greater than 3. The results from our bivariate linear regression confirm this finding, adding that being in the treatment group increases the probability of making a charitable donation by 0.004 percent. The third model we use to confirm our results is a probit model. The probit model confirms wht we see in both the t-test as well as the linear regression, allowing us to conclude that we have sufficient statistical evidence to conclude that the treatment has a positive effect on the likelihood of giving.\n\nT-test between the treatment and control groups on the binary outcome of whether any charitable donation was made.\n\n#split data into treatment and control\ncontrol_df &lt;- data[data$treatment == 0, ]\ntreatment_df &lt;- data[data$treatment == 1, ]\n\n# create data for ttest\nmean_control &lt;- mean(control_df$gave, na.rm = TRUE)\nsd_control &lt;- sd(control_df$gave, na.rm = TRUE)\nN_control &lt;- length(control_df$gave)\n\nmean_treatment &lt;- mean(treatment_df$gave, na.rm = TRUE)\nsd_treatment &lt;- sd(treatment_df$gave, na.rm = TRUE)\nN_treatment &lt;- length(treatment_df$gave)\n  \n# calculate tstat\nt_stat &lt;- (mean_control - mean_treatment) / sqrt((sd_control^2 / N_control) + (sd_treatment^2 / N_treatment))\nprint(t_stat)\n\n[1] -3.209462\n\n\n\n\nBi-Variate Linear Regression for whether any charitable donation was made.\n\ngave_lm &lt;- lm(gave~treatment, data=data)\nsummary(gave_lm)\n\n\nCall:\nlm(formula = gave ~ treatment, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02204 -0.02204 -0.02204 -0.01786  0.98214 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.017858   0.001101  16.225  &lt; 2e-16 ***\ntreatment   0.004180   0.001348   3.101  0.00193 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50081 degrees of freedom\nMultiple R-squared:  0.000192,  Adjusted R-squared:  0.0001721 \nF-statistic: 9.618 on 1 and 50081 DF,  p-value: 0.001927\n\n\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n# Fit the probit regression model\nprobit &lt;- glm(gave ~ treatment, data = data, family = binomial(link = \"probit\"))\nsummary(probit)\n\n\nCall:\nglm(formula = gave ~ treatment, family = binomial(link = \"probit\"), \n    data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.10014    0.02332 -90.074  &lt; 2e-16 ***\ntreatment    0.08678    0.02788   3.113  0.00185 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10061  on 50081  degrees of freedom\nAIC: 10065\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nWe use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. Our results show that the match threshold does not have a statistically significant effect on whether or not people donate. Although this result goes against conventional wisdom, the finding aligns with what was observed in the study.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\n\n# Perform a t-test on outcome1\ntest12 &lt;- t.test(gave ~ ratio, data = subset(data, ratio %in% c(1, 2)))\ntest13 &lt;- t.test(gave ~ ratio, data = subset(data, ratio %in% c(1, 3)))\ntest23 &lt;- t.test(gave ~ ratio, data = subset(data, ratio %in% c(2, 3)))\n\n# Print results\nprint(test12)\n\n\n    Welch Two Sample t-test\n\ndata:  gave by ratio\nt = -0.96505, df = 22225, p-value = 0.3345\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -0.005711275  0.001942773\nsample estimates:\nmean in group 1 mean in group 2 \n     0.02074912      0.02263338 \n\nprint(test13)\n\n\n    Welch Two Sample t-test\n\ndata:  gave by ratio\nt = -1.015, df = 22215, p-value = 0.3101\nalternative hypothesis: true difference in means between group 1 and group 3 is not equal to 0\n95 percent confidence interval:\n -0.005816051  0.001847501\nsample estimates:\nmean in group 1 mean in group 3 \n     0.02074912      0.02273340 \n\nprint(test23)\n\n\n    Welch Two Sample t-test\n\ndata:  gave by ratio\nt = -0.050116, df = 22261, p-value = 0.96\nalternative hypothesis: true difference in means between group 2 and group 3 is not equal to 0\n95 percent confidence interval:\n -0.004012044  0.003811996\nsample estimates:\nmean in group 2 mean in group 3 \n     0.02263338      0.02273340 \n\n\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\nTo test the claim that the match threshold has no significant impact on whether or not someone decides to give, we execute a logistic regression, regressing gave on ratio1, ratio2, and ratio3. This test will tell us how each ratio effects the odds of someone giving anything. The coefficient for ratio 1 is positive but not statistically significant, meaning that the effect of the 1:1 ratio is not statistically significant from the effect observed when no match is offered. The effect of ratio’s 2 and 3 are both positive and statistically significant. Notably, their coefficients are nearly exactly the same, which shows tht the difference between a 2:1 ratio and a 3:1 ratio is essentially the same.\n\n# Create 'ratio1' \ndata &lt;- data %&gt;%\n  mutate(ratio1 = as.integer(ratio == 1))\n\n# Fit a logistic regression model\nmodel &lt;- glm(gave ~ ratio1 + ratio2 + ratio3, family = binomial(), data = data)\n\n# Summary of the model\nsummary(model)\n\n\nCall:\nglm(formula = gave ~ ratio1 + ratio2 + ratio3, family = binomial(), \n    data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -4.00727    0.05844 -68.565  &lt; 2e-16 ***\nratio1       0.15299    0.08852   1.728  0.08394 .  \nratio2       0.24184    0.08646   2.797  0.00516 ** \nratio3       0.24635    0.08637   2.852  0.00434 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10060  on 50079  degrees of freedom\nAIC: 10068\n\nNumber of Fisher Scoring iterations: 6\n\n\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n# create data subsets\nratio1_data &lt;- data[data$ratio == 1, ]\nratio2_data &lt;- data[data$ratio == 2, ]\nratio3_data &lt;- data[data$ratio == 3, ]\n\n# Calculate the mean of 'gave' for the subsets\nratio1_rr &lt;- mean(ratio1_data$gave, na.rm = TRUE) \nratio2_rr &lt;- mean(ratio2_data$gave, na.rm = TRUE) \nratio3_rr &lt;- mean(ratio3_data$gave, na.rm = TRUE) \n\nprint(ratio1_rr)\n\n[1] 0.02074912\n\nprint(ratio2_rr)\n\n[1] 0.02263338\n\nprint(ratio3_rr)\n\n[1] 0.0227334\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis? To measure the effect we run a bivariate linear regression of the donation amount on the treatment status. In the summary of this regression, we see that being in the treatment group has a positive effect on the size of the matched donation that is statistically significant at the 90 percent level.\n\namount_lm &lt;- lm(amount~treatment, data=data)\nsummary(amount_lm)\n\n\nCall:\nlm(formula = amount ~ treatment, data = data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -0.97  -0.97  -0.97  -0.81 399.03 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.81327    0.06742  12.063   &lt;2e-16 ***\ntreatment    0.15361    0.08256   1.861   0.0628 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.709 on 50081 degrees of freedom\nMultiple R-squared:  6.911e-05, Adjusted R-squared:  4.915e-05 \nF-statistic: 3.461 on 1 and 50081 DF,  p-value: 0.06282\n\n\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\nRepeating the analysis above using only the data from people who made a contribution, we are able to measure how much respondents donate conditional on donating some positive amount. In this case, we see that being in the treatment group has a negative impact, however, this impact is not statistically significant. This tells us that we are unsure whether the treatment is actually effecting the amount that people decide to give. Becuase our treatment coefficient is insignificant, we cannot conclude that the treatment has any effect on the amount that people decide to give. For this reason, we conclude that we do not have sufficient evidence to state that the treatment has a causal effect on the outcome.\n\ngivers_only &lt;- data[data$amount &gt; 0, ]\namount_lm &lt;- lm(amount~treatment, data=givers_only)\nsummary(amount_lm)\n\n\nCall:\nlm(formula = amount ~ treatment, data = givers_only)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-43.54 -23.87 -18.87   6.13 356.13 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   45.540      2.423  18.792   &lt;2e-16 ***\ntreatment     -1.668      2.872  -0.581    0.561    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.83 on 1032 degrees of freedom\nMultiple R-squared:  0.0003268, Adjusted R-squared:  -0.0006419 \nF-statistic: 0.3374 on 1 and 1032 DF,  p-value: 0.5615\n\n\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\n# control group givers\ngivers_control &lt;- control_df[control_df$amount &gt; 0, ]\n\n# Calculate the mean of the donation amounts\nmean_amount &lt;- mean(givers_control$amount)\n\n# Creating the histogram with a vertical line indicating the mean\nhistogram1 &lt;- ggplot(givers_control, aes(x = amount)) +\n  geom_histogram(binwidth = 10, fill = \"blue\", color = \"black\") +  # Histogram\n  geom_vline(aes(xintercept = mean_amount), color = \"red\", linetype = \"dashed\", size = 1) +  # Mean line\n  labs(title = \"Donation Amounts (Control Group)\",\n       x = \"Donation Amount\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  ggtitle(paste(\"Control Group Donation Amounts with Mean at $\", round(mean_amount, 2)))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n# Print the histogram\nprint(histogram1)\n\n\n\n\n\n\n\n\n\n# treatment group givers\ngivers_treatment &lt;- treatment_df[treatment_df$amount &gt; 0, ]\n\n# Calculate the mean of the donation amounts\nmean_amount &lt;- mean(givers_treatment$amount)\n\n# Creating the histogram with a vertical line indicating the mean\nhistogram1 &lt;- ggplot(givers_treatment, aes(x = amount)) +\n  geom_histogram(binwidth = 10, fill = \"blue\", color = \"black\") +  # Histogram\n  geom_vline(aes(xintercept = mean_amount), color = \"red\", linetype = \"dashed\", size = 1) +  # Mean line\n  labs(title = \"Donation Amounts (Treatment Group)\",\n       x = \"Donation Amount\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  ggtitle(paste(\"Treatment Group Donation Amounts with Mean at $\", round(mean_amount, 2)))\n\n# Print the histogram\nprint(histogram1)"
  },
  {
    "objectID": "projects/project1/hw1_questions.html#simulation-experiment",
    "href": "projects/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nThis first plot is a demonstration of the Law of Large Numbers. This law states that as your sample size increases, you can expect your sample average to get closer to the true mean. To recreate this, we first simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. Next, we calculate a vector of 10,000 differences and then plot the cumulative average of that vector of differences. The plot shows that as we increase our sample size, the sample mean gets closer to the true mean. In our case, the sample mean never actually approaches the true difference in means. One simple way to fix this would be to increase our sample size beyond 10,000. to do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n# number of simulations\nn &lt;- 10000\n\n# probability of success\np_c &lt;- 0.018\np_t &lt;- 0.022\n\n# True mean difference\ntrue_diff &lt;- p_t - p_c\n\n# simulated draws\nset.seed(10)\ncontrol_sim &lt;- rbinom(n,size = 1, prob = p_c)\ntreatment_sim &lt;- rbinom(n,size = 1, prob = p_t)\n\n# Calculate cumulative means for both simulations\ncummean_control &lt;- cumsum(control_sim) / (1:n)\ncummean_treatment &lt;- cumsum(treatment_sim) / (1:n)\n\n# Calculate the cumulative differences\nsample_cumdiff &lt;- cummean_treatment - cummean_control\n\n# Create a data frame for plotting\nplot_data &lt;- data.frame(\n  Simulation = 1:n,\n  CumulativeDifference = sample_cumdiff\n)\n\n\n# Generate the plot\nggplot(plot_data, aes(x = Simulation, y = CumulativeDifference)) +\n  geom_line(color = \"red\") + \n  geom_hline(yintercept = true_diff, linetype = \"dashed\", color = \"blue\") + \n  labs(title = \"Cumulative Difference Between Treatment and Control\",\n       x = \"Number of Simulations\",\n       y = \"Cumulative Difference\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.” To demonstrate the Central Limit Theorem we create histograms showing us the average difference between the treatment and control group from simulations of different sample sizes. The sample sizes we tested are 50, 200, 500, and 1000. As you can see in the plots, there are less observations in the tails of the data as the sample size increases. This observation validates the Central Limit Theorem because it shows that as we increase sample size the sample statistic gets closer to the true value. It is also worth noting that the value zero is in the middle of the distribution in each histogram.\n\n# Number of repetitions\nreps &lt;- 1000\n\n# Different numbers of draws\ndraw_sizes &lt;- c(50, 200, 500, 1000)\n\n# Probabilities for control and treatment groups\np_c &lt;- 0.018\np_t &lt;- 0.022\n\n# Set a seed for reproducibility\nset.seed(10)\n\n# Loop over each draw size\nfor (draws in draw_sizes) {\n    # Initialize a vector to store the average differences for the current draw size\n    mean_diff &lt;- numeric(reps)\n    \n    # Repeat draw and calculation for the current number of draws\n    for (i in 1:reps) {\n        # Simulate draws from Bernoulli distributions for control and treatment\n        c_sim &lt;- rbinom(draws, size = 1, prob = p_c)\n        t_sim &lt;- rbinom(draws, size = 1, prob = p_t)\n    \n        # Calculate the average difference and store it\n        mean_diff[i] &lt;- mean(t_sim) - mean(c_sim)\n    }\n    \n    # Visualize the distribution of average differences for the current draw size\n    plot_data &lt;- data.frame(AverageDifferences = mean_diff)\n    p &lt;- ggplot(plot_data, aes(x = AverageDifferences)) +\n        geom_histogram(bins = 30, fill = \"dodgerblue\", color = \"black\") +\n        labs(title = paste(\"Histogram of Average Differences for\", draws, \"Draws\"),\n             x = \"Average Difference\",\n             y = \"Frequency\") +\n        theme_minimal()\n    \n    print(p)  # Display the plot\n}"
  },
  {
    "objectID": "projects/project2/hw2_questions.html",
    "href": "projects/project2/hw2_questions.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nTo begin our analysis, we first need to read in the data.\n\n# read in the data\nblueprinty &lt;- read.csv(\"~/My_Quarto_Website/projects/project2/blueprinty.csv\")\n\nWe want to use this ddata to provide insights as to whether or not firms using Blueprinty’s software are more successful in getting their patent applications approved. We first visualize our data to see if there is an obvious difference in the number of patens approved between customers and non-customers. The plot blow shows a roughly similar distribution between both groups. One notable difference is that, for customers, we see more volume centered around 4 while the non-customers’ number of patents approved seems to be equally likely to be between 0 and 4. We cannot be certain looking at the plots alone, so we contimue by looking at the average number of patents approved but customer status.\n\ncustomers &lt;- blueprinty[blueprinty$iscustomer == 1, ]\nnoncustomers &lt;- blueprinty[blueprinty$iscustomer == 0, ]\n\n# Plot the first histogram\nhist(noncustomers$patents, \n     col = \"blue\", \n     main = \"Histogram Comparison\", \n     xlab = \"Number of Patents\", \n     ylab = \"Frequency\",\n     ylim = c(0, max(hist(noncustomers$patents)$counts, hist(customers$patents)$counts))\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Add the second histogram to the same plot\nhist(customers$patents, \n     col = \"red\", \n     add = TRUE\n)\n\n# Add a legend\nlegend(\"topright\", \n       legend = c(\"Non-Customers\", \"Customers\"), \n       fill = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\nThe means for both groups are listed below. The mean for patents approved is roughly the same between customers and non-customers, but we can not be sure if there is a statistically significant difference between the two groups by simply comparing the means. To get more insights we can use linear regression to test the effect of being a customer.\n\n#split data into customer and non-customer\ncustomers &lt;- blueprinty[blueprinty$iscustomer == 1, ]\nnoncustomers &lt;- blueprinty[blueprinty$iscustomer == 0, ]\n\npatent_mean_c &lt;- mean(customers$patents) \npatent_mean_nc &lt;- mean(noncustomers$patents)\n\nprint(patent_mean_c)\n\n[1] 4.091371\n\nprint(patent_mean_nc)\n\n[1] 3.623177\n\n\nOur linear model estimates that there is indeed a positive causal effect from being a customer on the number of patents that are approved. This finding is statistically significant at the 95 percent level.\n\npatents_lm &lt;- lm(patents~iscustomer, data=blueprinty)\nsummary(patents_lm)\n\n\nCall:\nlm(formula = patents ~ iscustomer, data = blueprinty)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0914 -1.6232 -0.6232  1.3768 12.3768 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.62318    0.06505  55.702  &lt; 2e-16 ***\niscustomer   0.46819    0.17949   2.609  0.00918 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.348 on 1498 degrees of freedom\nMultiple R-squared:  0.004522,  Adjusted R-squared:  0.003857 \nF-statistic: 6.804 on 1 and 1498 DF,  p-value: 0.009184\n\n\nDespite our findings, we must note that Blueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers. To check whether or not there is a systematic difference in the composition of the group, we will look at the group level compositions for both customers and non-customers. In the plots below, we compare the distributions for age and region.\n\n\nLooking at the distribution of region for customers and nun-customers, we see a distribution that is mostly similar. Most of the members in the data are either located in the Northeast or the Southwest, with each of the three remaining region seemingly being equally proportioned among the remaining data. Given the similar distributions for the groups, we do not see evidence of a systematic difference between customers and non-customers when comparing regions.\n\n# Get frequency counts for each group in column_name1\ngroup_counts1 &lt;- table(noncustomers$region)\n\n# Plot a bar plot of the frequency counts for column_name1\nbarplot(group_counts1,\n        main = \"Region Frequency Comparison\",\n        xlab = \"Regions\",\n        ylab = \"Frequency\",\n        col = \"blue\",\n        border = \"black\"\n)\n\n# Get frequency counts for each group in column_name2\ngroup_counts2 &lt;- table(customers$region)\n\n# Add the bar plot of the frequency counts for column_name2 to the existing plot\nbarplot(group_counts2,\n        col = \"red\",\n        add = TRUE\n)\n\n# Add a legend\nlegend(\"topright\",\n       legend = c(\"Non-Customer\", \"Customer\"),\n       fill = c(\"blue\", \"red\")\n)\n\n\n\n\n\n\n\n\n\n\n\nWhen comparing the ages between the customer and non-customer groups we see a difference between the distribution of ages. The age data for customers is skewed right, while the data for non-customers is shaped more like a bell curve. This difference translates to the customer group being younger on average than the non-customer group. With this difference in mind, we have reason to believe that there may be a systematic difference between the customer and non-customer group that we will likely want to account for prior to drawing any conclusions.\n\n# Plot the first histogram\nhist(noncustomers$age, \n     col = \"blue\", \n     main = \"Histogram Comparison\", \n     xlab = \"Age\", \n     ylab = \"Frequency\",\n     ylim = c(0, max(hist(noncustomers$age)$counts, hist(customers$age)$counts))\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Add the second histogram to the same plot\nhist(customers$age, \n     col = \"red\", \n     add = TRUE\n)\n\n# Add a legend\nlegend(\"topright\", \n       legend = c(\"Non-Customers\", \"Customers\"), \n       fill = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe mathematical likelihood for a Poisson distribution is as follows: \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nNext, we plot the Poisson likelihood (as well as the log-likelihood) as a function of using the number of patents observed as the input for Y.\n\npoisson_log_likelihood &lt;- function(lambda, Y){\n   log_likelihood &lt;- -lambda + sum(Y * log(lambda)) - sum(log(factorial(Y)))\n   return(sum(log_likelihood))\n}\n\n\n# Use the patents column from the blueprinty dataset\nY &lt;- blueprinty$patents\n\n# Create a sequence of lambda values\nlambda_values &lt;- seq(0.1, 20, by = 0.1)  # Start from 0.1 to avoid lambda = 0\n\n# Calculate log-likelihood for each lambda value using the vector of patents\nlog_likelihood_values &lt;- sapply(lambda_values, function(lambda) poisson_log_likelihood(lambda, Y))\n\n# Plot log-likelihood\nplot(lambda_values, log_likelihood_values, type = \"l\", col = \"red\", xlab = \"Lambda\", ylab = \"Log-Likelihood\", main = \"Poisson Log-Likelihood\", ylim = range(log_likelihood_values, na.rm = TRUE))\n\n\n\n\n\n\n\n\nWe can use calculus to optimize our likelihood function by taking the first derivative of our log-likelihood function and setting it equal to zero to solve for lambda.\nThe log-likelihood function for the Poisson distribution is:\n\\(\\log L(\\lambda) = -\\lambda + Y \\log(\\lambda) - \\log(Y!)\\)\nTaking the derivative with respect to ( \\(\\lambda\\) ):\n\\(\\frac{d}{d\\lambda} \\log L(\\lambda) = -1 + \\frac{Y}{\\lambda}\\)\nSetting the derivative equal to zero and solving for ( \\(\\lambda\\) ):\n\\(-1 + \\frac{Y}{\\lambda} = 0\\)\n\\(\\frac{Y}{\\lambda} = 1\\)\n\\(\\lambda = Y\\)\nSo, the maximum likelihood estimate of ( \\(\\lambda\\) ) for the Poisson distribution is ( \\(\\lambda\\) = Y ), which is to be expected given that the mean of a Poisson distribution is lambda (\\(\\lambda\\)).\nWe can also find the maximum likelihood estimate (MLE) of ( \\(\\lambda\\)) for the Poisson distribution by optimizing the log-likelihood function using R’s optim() function. Here’s how we can do it:\n\n# Define the log-likelihood function for the Poisson distribution\npoisson_log_likelihood &lt;- function(lambda, Y){\n   -sum(dpois(Y, lambda, log = TRUE))\n}\n\n# Use the patents column from the blueprinty dataset\nY &lt;- blueprinty$patents\n\n# Use optim() to find the MLE\nmle_result &lt;- optim(par = 1, fn = poisson_log_likelihood, Y = Y, lower = 0.01, upper = 20, method = \"Brent\")\n\n# Extract the MLE\nlambda_mle &lt;- mle_result$par\nlambda_mle\n\n[1] 3.684667\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n# Convert region to factor\nblueprinty$region &lt;- as.factor(blueprinty$region)\n\n# Create covariate matrix X\nX &lt;- cbind(1, blueprinty$age, blueprinty$age^2, model.matrix(~ -1 + region, data = blueprinty), blueprinty$iscustomer)\ny &lt;- blueprinty$patents\n\n# Update likelihood function for Poisson regression\npoisson_reg_ll &lt;- function(beta, X, y){\n   lambda &lt;- exp(X %*% beta)\n   log_likelihood &lt;- -sum(dpois(y, lambda, log = TRUE))\n  return(log_likelihood)\n}\n\n\n## Use optim() to find the MLE vector and the Hessian\n#out &lt;- optim(par = rep(0, ncol(X)), fn = poisson_reg_ll, X = X, y = y, hessian = FALSE, control = list(fnscale = -1), method = \"Nelder-Mead\")\n\n\n## Calculate standard errors of beta parameter estimates\n#Hinv &lt;- -solve(out$hessian)\n#results &lt;- cbind(coefs = out$par, sterr = sqrt(diag(Hinv)))\n#rownames(results) &lt;- colnames(X)\n#results &lt;- round(results, 4)\n\n## Display coefficients and standard errors\n#results\n\nWe can test the validity of our results using a generalized linear model.\n\n# Fit a Poisson regression model using glm\nglm_model &lt;- glm(patents ~ age + I(age^2) + region + iscustomer, data = blueprinty, family = \"poisson\")\n\n# Display summary of the glm model\nsummary(glm_model)\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = \"poisson\", data = blueprinty)\n\nCoefficients:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.4512823  0.1836301  -2.458  0.01399 *  \nage              0.1445364  0.0138793  10.414  &lt; 2e-16 ***\nI(age^2)        -0.0028681  0.0002577 -11.131  &lt; 2e-16 ***\nregionNortheast  0.0985960  0.0420070   2.347  0.01892 *  \nregionNorthwest -0.0200942  0.0537833  -0.374  0.70869    \nregionSouth      0.0571720  0.0526757   1.085  0.27776    \nregionSouthwest  0.0513470  0.0472124   1.088  0.27678    \niscustomer       0.1181144  0.0389204   3.035  0.00241 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2178.8  on 1492  degrees of freedom\nAIC: 6567.7\n\nNumber of Fisher Scoring iterations: 5\n\n\nInterpreting the results of our regression we can cnofirm that being a customer has a positive and statistically significant impact on the likelihood of a patent application being approved. This finding supports the initial claim that firms using Blueprinty’s software are more successful in getting their patent applications approved. Our regression results are also telling us that age and region have a statistically significant effect on patent outcomes. This finding is consistent with the differences we had observed in patent outcomes and age/region distributions between customers and non customers. Given our results, it would be wise for a firm to consider becoming a customer to realize the effects of Blueprinty’s software on patent success."
  },
  {
    "objectID": "projects/project2/hw2_questions.html#blueprinty-case-study",
    "href": "projects/project2/hw2_questions.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty’s software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty’s software and after using it. unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm’s number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty’s software. The marketing team would like to use this data to make the claim that firms using Blueprinty’s software are more successful in getting their patent applications approved.\n\n\n\nTo begin our analysis, we first need to read in the data.\n\n# read in the data\nblueprinty &lt;- read.csv(\"~/My_Quarto_Website/projects/project2/blueprinty.csv\")\n\nWe want to use this ddata to provide insights as to whether or not firms using Blueprinty’s software are more successful in getting their patent applications approved. We first visualize our data to see if there is an obvious difference in the number of patens approved between customers and non-customers. The plot blow shows a roughly similar distribution between both groups. One notable difference is that, for customers, we see more volume centered around 4 while the non-customers’ number of patents approved seems to be equally likely to be between 0 and 4. We cannot be certain looking at the plots alone, so we contimue by looking at the average number of patents approved but customer status.\n\ncustomers &lt;- blueprinty[blueprinty$iscustomer == 1, ]\nnoncustomers &lt;- blueprinty[blueprinty$iscustomer == 0, ]\n\n# Plot the first histogram\nhist(noncustomers$patents, \n     col = \"blue\", \n     main = \"Histogram Comparison\", \n     xlab = \"Number of Patents\", \n     ylab = \"Frequency\",\n     ylim = c(0, max(hist(noncustomers$patents)$counts, hist(customers$patents)$counts))\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Add the second histogram to the same plot\nhist(customers$patents, \n     col = \"red\", \n     add = TRUE\n)\n\n# Add a legend\nlegend(\"topright\", \n       legend = c(\"Non-Customers\", \"Customers\"), \n       fill = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\nThe means for both groups are listed below. The mean for patents approved is roughly the same between customers and non-customers, but we can not be sure if there is a statistically significant difference between the two groups by simply comparing the means. To get more insights we can use linear regression to test the effect of being a customer.\n\n#split data into customer and non-customer\ncustomers &lt;- blueprinty[blueprinty$iscustomer == 1, ]\nnoncustomers &lt;- blueprinty[blueprinty$iscustomer == 0, ]\n\npatent_mean_c &lt;- mean(customers$patents) \npatent_mean_nc &lt;- mean(noncustomers$patents)\n\nprint(patent_mean_c)\n\n[1] 4.091371\n\nprint(patent_mean_nc)\n\n[1] 3.623177\n\n\nOur linear model estimates that there is indeed a positive causal effect from being a customer on the number of patents that are approved. This finding is statistically significant at the 95 percent level.\n\npatents_lm &lt;- lm(patents~iscustomer, data=blueprinty)\nsummary(patents_lm)\n\n\nCall:\nlm(formula = patents ~ iscustomer, data = blueprinty)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.0914 -1.6232 -0.6232  1.3768 12.3768 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.62318    0.06505  55.702  &lt; 2e-16 ***\niscustomer   0.46819    0.17949   2.609  0.00918 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.348 on 1498 degrees of freedom\nMultiple R-squared:  0.004522,  Adjusted R-squared:  0.003857 \nF-statistic: 6.804 on 1 and 1498 DF,  p-value: 0.009184\n\n\nDespite our findings, we must note that Blueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers. To check whether or not there is a systematic difference in the composition of the group, we will look at the group level compositions for both customers and non-customers. In the plots below, we compare the distributions for age and region.\n\n\nLooking at the distribution of region for customers and nun-customers, we see a distribution that is mostly similar. Most of the members in the data are either located in the Northeast or the Southwest, with each of the three remaining region seemingly being equally proportioned among the remaining data. Given the similar distributions for the groups, we do not see evidence of a systematic difference between customers and non-customers when comparing regions.\n\n# Get frequency counts for each group in column_name1\ngroup_counts1 &lt;- table(noncustomers$region)\n\n# Plot a bar plot of the frequency counts for column_name1\nbarplot(group_counts1,\n        main = \"Region Frequency Comparison\",\n        xlab = \"Regions\",\n        ylab = \"Frequency\",\n        col = \"blue\",\n        border = \"black\"\n)\n\n# Get frequency counts for each group in column_name2\ngroup_counts2 &lt;- table(customers$region)\n\n# Add the bar plot of the frequency counts for column_name2 to the existing plot\nbarplot(group_counts2,\n        col = \"red\",\n        add = TRUE\n)\n\n# Add a legend\nlegend(\"topright\",\n       legend = c(\"Non-Customer\", \"Customer\"),\n       fill = c(\"blue\", \"red\")\n)\n\n\n\n\n\n\n\n\n\n\n\nWhen comparing the ages between the customer and non-customer groups we see a difference between the distribution of ages. The age data for customers is skewed right, while the data for non-customers is shaped more like a bell curve. This difference translates to the customer group being younger on average than the non-customer group. With this difference in mind, we have reason to believe that there may be a systematic difference between the customer and non-customer group that we will likely want to account for prior to drawing any conclusions.\n\n# Plot the first histogram\nhist(noncustomers$age, \n     col = \"blue\", \n     main = \"Histogram Comparison\", \n     xlab = \"Age\", \n     ylab = \"Frequency\",\n     ylim = c(0, max(hist(noncustomers$age)$counts, hist(customers$age)$counts))\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Add the second histogram to the same plot\nhist(customers$age, \n     col = \"red\", \n     add = TRUE\n)\n\n# Add a legend\nlegend(\"topright\", \n       legend = c(\"Non-Customers\", \"Customers\"), \n       fill = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\n\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\nThe mathematical likelihood for a Poisson distribution is as follows: \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nNext, we plot the Poisson likelihood (as well as the log-likelihood) as a function of using the number of patents observed as the input for Y.\n\npoisson_log_likelihood &lt;- function(lambda, Y){\n   log_likelihood &lt;- -lambda + sum(Y * log(lambda)) - sum(log(factorial(Y)))\n   return(sum(log_likelihood))\n}\n\n\n# Use the patents column from the blueprinty dataset\nY &lt;- blueprinty$patents\n\n# Create a sequence of lambda values\nlambda_values &lt;- seq(0.1, 20, by = 0.1)  # Start from 0.1 to avoid lambda = 0\n\n# Calculate log-likelihood for each lambda value using the vector of patents\nlog_likelihood_values &lt;- sapply(lambda_values, function(lambda) poisson_log_likelihood(lambda, Y))\n\n# Plot log-likelihood\nplot(lambda_values, log_likelihood_values, type = \"l\", col = \"red\", xlab = \"Lambda\", ylab = \"Log-Likelihood\", main = \"Poisson Log-Likelihood\", ylim = range(log_likelihood_values, na.rm = TRUE))\n\n\n\n\n\n\n\n\nWe can use calculus to optimize our likelihood function by taking the first derivative of our log-likelihood function and setting it equal to zero to solve for lambda.\nThe log-likelihood function for the Poisson distribution is:\n\\(\\log L(\\lambda) = -\\lambda + Y \\log(\\lambda) - \\log(Y!)\\)\nTaking the derivative with respect to ( \\(\\lambda\\) ):\n\\(\\frac{d}{d\\lambda} \\log L(\\lambda) = -1 + \\frac{Y}{\\lambda}\\)\nSetting the derivative equal to zero and solving for ( \\(\\lambda\\) ):\n\\(-1 + \\frac{Y}{\\lambda} = 0\\)\n\\(\\frac{Y}{\\lambda} = 1\\)\n\\(\\lambda = Y\\)\nSo, the maximum likelihood estimate of ( \\(\\lambda\\) ) for the Poisson distribution is ( \\(\\lambda\\) = Y ), which is to be expected given that the mean of a Poisson distribution is lambda (\\(\\lambda\\)).\nWe can also find the maximum likelihood estimate (MLE) of ( \\(\\lambda\\)) for the Poisson distribution by optimizing the log-likelihood function using R’s optim() function. Here’s how we can do it:\n\n# Define the log-likelihood function for the Poisson distribution\npoisson_log_likelihood &lt;- function(lambda, Y){\n   -sum(dpois(Y, lambda, log = TRUE))\n}\n\n# Use the patents column from the blueprinty dataset\nY &lt;- blueprinty$patents\n\n# Use optim() to find the MLE\nmle_result &lt;- optim(par = 1, fn = poisson_log_likelihood, Y = Y, lower = 0.01, upper = 20, method = \"Brent\")\n\n# Extract the MLE\nlambda_mle &lt;- mle_result$par\nlambda_mle\n\n[1] 3.684667\n\n\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\n\n# Convert region to factor\nblueprinty$region &lt;- as.factor(blueprinty$region)\n\n# Create covariate matrix X\nX &lt;- cbind(1, blueprinty$age, blueprinty$age^2, model.matrix(~ -1 + region, data = blueprinty), blueprinty$iscustomer)\ny &lt;- blueprinty$patents\n\n# Update likelihood function for Poisson regression\npoisson_reg_ll &lt;- function(beta, X, y){\n   lambda &lt;- exp(X %*% beta)\n   log_likelihood &lt;- -sum(dpois(y, lambda, log = TRUE))\n  return(log_likelihood)\n}\n\n\n## Use optim() to find the MLE vector and the Hessian\n#out &lt;- optim(par = rep(0, ncol(X)), fn = poisson_reg_ll, X = X, y = y, hessian = FALSE, control = list(fnscale = -1), method = \"Nelder-Mead\")\n\n\n## Calculate standard errors of beta parameter estimates\n#Hinv &lt;- -solve(out$hessian)\n#results &lt;- cbind(coefs = out$par, sterr = sqrt(diag(Hinv)))\n#rownames(results) &lt;- colnames(X)\n#results &lt;- round(results, 4)\n\n## Display coefficients and standard errors\n#results\n\nWe can test the validity of our results using a generalized linear model.\n\n# Fit a Poisson regression model using glm\nglm_model &lt;- glm(patents ~ age + I(age^2) + region + iscustomer, data = blueprinty, family = \"poisson\")\n\n# Display summary of the glm model\nsummary(glm_model)\n\n\nCall:\nglm(formula = patents ~ age + I(age^2) + region + iscustomer, \n    family = \"poisson\", data = blueprinty)\n\nCoefficients:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)     -0.4512823  0.1836301  -2.458  0.01399 *  \nage              0.1445364  0.0138793  10.414  &lt; 2e-16 ***\nI(age^2)        -0.0028681  0.0002577 -11.131  &lt; 2e-16 ***\nregionNortheast  0.0985960  0.0420070   2.347  0.01892 *  \nregionNorthwest -0.0200942  0.0537833  -0.374  0.70869    \nregionSouth      0.0571720  0.0526757   1.085  0.27776    \nregionSouthwest  0.0513470  0.0472124   1.088  0.27678    \niscustomer       0.1181144  0.0389204   3.035  0.00241 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 2362.5  on 1499  degrees of freedom\nResidual deviance: 2178.8  on 1492  degrees of freedom\nAIC: 6567.7\n\nNumber of Fisher Scoring iterations: 5\n\n\nInterpreting the results of our regression we can cnofirm that being a customer has a positive and statistically significant impact on the likelihood of a patent application being approved. This finding supports the initial claim that firms using Blueprinty’s software are more successful in getting their patent applications approved. Our regression results are also telling us that age and region have a statistically significant effect on patent outcomes. This finding is consistent with the differences we had observed in patent outcomes and age/region distributions between customers and non customers. Given our results, it would be wise for a firm to consider becoming a customer to realize the effects of Blueprinty’s software on patent success."
  },
  {
    "objectID": "projects/project2/hw2_questions.html#airbnb-case-study",
    "href": "projects/project2/hw2_questions.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\n\n\nData\nTo begin our analysis, we first need to read in the data.\n\n# read in the data\nairbnb &lt;- read.csv(\"~/My_Quarto_Website/projects/project2/airbnb.csv\")\n\n# Function to replace NA with mode\nna_to_mode &lt;- function(x) {\n  if (is.factor(x) | is.character(x)) {\n    mode_val &lt;- as.character(which.max(table(x)))\n    x[is.na(x)] &lt;- mode_val\n  } else {\n    mode_val &lt;- as.numeric(names(which.max(table(x))))\n    x[is.na(x)] &lt;- mode_val\n  }\n  return(x)\n}\n\n# Apply the function to each column\nairbnb_clean &lt;- as.data.frame(lapply(airbnb, na_to_mode))\n\n\nVisualizing the Response Variable\n\nlibrary(ggplot2)\nggplot(airbnb_clean, aes(x = airbnb_clean$number_of_reviews)) +\n  geom_histogram()\n\nWarning: Use of `airbnb_clean$number_of_reviews` is discouraged.\nℹ Use `number_of_reviews` instead.\n\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\nmax(airbnb_clean$number_of_reviews)\n\n[1] 421\n\n\n\n\n\nModeling the data\nThe Poisson regression model explores the factors influencing the number of reviews for Airbnb listings. The intercept (5.537) represents the expected number of reviews when all other variables are zero, which is not practically meaningful in this context. For each additional day of availability, the expected number of reviews increases by a factor of 1.00005021. Private rooms are associated with a 14.57% decrease, and shared rooms with a 41.71% decrease in the expected number of reviews compared to entire home/apartment listings. Each additional bathroom is linked to a 11.61% decrease, while each additional bedroom corresponds to a 7.02% increase in the expected number of reviews. Higher prices are associated with a slight decrease in reviews, with each unit increase leading to a 0.024% decrease. Higher review scores for cleanliness, location, and value are associated with increases in the expected number of reviews. Lastly, listings that are instant bookable have an expected 34.68% increase in reviews compared to non-instant bookable listings.\n\nmodel &lt;- glm(number_of_reviews ~ days + room_type + bathrooms + bedrooms + price + review_scores_cleanliness +review_scores_location + review_scores_value + instant_bookable, data = airbnb_clean , family = poisson)\n\nsummary(model)\n\n\nCall:\nglm(formula = number_of_reviews ~ days + room_type + bathrooms + \n    bedrooms + price + review_scores_cleanliness + review_scores_location + \n    review_scores_value + instant_bookable, family = poisson, \n    data = airbnb_clean)\n\nCoefficients:\n                            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)                5.537e+00  1.289e-02  429.50   &lt;2e-16 ***\ndays                       5.021e-05  3.547e-07  141.56   &lt;2e-16 ***\nroom_typePrivate room     -1.457e-01  2.785e-03  -52.33   &lt;2e-16 ***\nroom_typeShared room      -4.171e-01  8.595e-03  -48.53   &lt;2e-16 ***\nbathrooms                 -1.161e-01  3.800e-03  -30.55   &lt;2e-16 ***\nbedrooms                   7.018e-02  1.990e-03   35.26   &lt;2e-16 ***\nprice                     -2.441e-04  1.082e-05  -22.55   &lt;2e-16 ***\nreview_scores_cleanliness  3.794e-02  1.454e-03   26.09   &lt;2e-16 ***\nreview_scores_location    -1.803e-01  1.541e-03 -116.99   &lt;2e-16 ***\nreview_scores_value       -1.480e-01  1.777e-03  -83.31   &lt;2e-16 ***\ninstant_bookablet          3.468e-01  2.875e-03  120.64   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1340709  on 40627  degrees of freedom\nResidual deviance: 1262681  on 40617  degrees of freedom\nAIC: 1386748\n\nNumber of Fisher Scoring iterations: 9\n\n\n\nRefining the Model"
  }
]