[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Warren Kennedy",
    "section": "",
    "text": "Warren Kennedy is an Operations Analyst at Midland Credit Management, an Encore Capital Group subsidiary. When not innovating on data platforms, Warren enjoys watching sports, walking his dogs, and overpaying for popcorn at movie theatres.\n\nEducation\nUC San Diego Rady School of Management | San Diego, CA\n\nMaster of Science in Business Analytics | August 2023 - December 2024\nBachelor of Arts in Economics | September 2021 - June 2023\n\n\n\nExperience\nMidland Credit Management | Operations Analyst | August 2023 - Present"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Warren Kennedy’s Resume",
    "section": "",
    "text": "Download PDF file."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\n\n\nWarren Kennedy\n\n\nApr 16, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/project1/index.html",
    "href": "projects/project1/index.html",
    "title": "Homework 1",
    "section": "",
    "text": "I like to plot data\n\n\nI also analyze data"
  },
  {
    "objectID": "projects/project1/index.html#sub-header",
    "href": "projects/project1/index.html#sub-header",
    "title": "Homework 1",
    "section": "",
    "text": "I also analyze data"
  },
  {
    "objectID": "index.html#sub-header",
    "href": "index.html#sub-header",
    "title": "Warren Kennedy",
    "section": "Sub-Header",
    "text": "Sub-Header"
  },
  {
    "objectID": "projects/project1/hw1_questions.html",
    "href": "projects/project1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment tests a variety of hypotheses, including whether matching donations increases the likelihood of a donation, whether the size of the match matters, and whether the size of the donation is affected by the match. To accomplish this, the authors used a variety of treatments, varying the price ratios for the match, the maximum matching grant amount, and the individual-specific ask amount. The treatments were letters used to solicit donations for a liberal politically motivated group that were sent to all 50 states. To control for spatial heterogeneity, the authors made sure that the treatment and control groups were balanced across states using demographic data, state and county election data, and data on the organization’s activity level within each state. Ultimately, the authors find that matching donations increases the likelihood of a donation, however, they also find that the size of the match does not matter, and that the size of the donation is not affected by the match.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#introduction",
    "href": "projects/project1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\nThe experiment tests a variety of hypotheses, including whether matching donations increases the likelihood of a donation, whether the size of the match matters, and whether the size of the donation is affected by the match. To accomplish this, the authors used a variety of treatments, varying the price ratios for the match, the maximum matching grant amount, and the individual-specific ask amount. The treatments were letters used to solicit donations for a liberal politically motivated group that were sent to all 50 states. To control for spatial heterogeneity, the authors made sure that the treatment and control groups were balanced across states using demographic data, state and county election data, and data on the organization’s activity level within each state. Ultimately, the authors find that matching donations increases the likelihood of a donation, however, they also find that the size of the match does not matter, and that the size of the donation is not affected by the match.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/project1/hw1_questions.html#data",
    "href": "projects/project1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\ntodo: Read the data into R/Python and describe the data The data used for this experiment has assigned roughly 2/3 of the individuals to the treatment group while assigning the remaining 1/3 of participants to be receive the standard mailing in the control group. Within the treatment group, we see that the different treatment features are evenly distributed across the treatment group participants\n\n# read the data \nlibrary(haven)\ndata &lt;- read_dta(\"/home/jovyan/My_Quarto_Website/projects/project1/karlan_list_2007.dta\")\n\n# summarize treatment/control split\ntreatment_perc &lt;- mean(data$treatment)\ncontrol_perc &lt;-mean(data$control)\n\n# Print the result\nprint(treatment_perc)\n\n[1] 0.6668131\n\nprint(control_perc)\n\n[1] 0.3331869\n\n\n\n# Create tables to show the distributions of the treatment features\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nratio_counts &lt;- data %&gt;%\n  count(ratio) %&gt;%\n  mutate(percentage = round(n / sum(n) * 100,2))\n\nsize_counts &lt;- data %&gt;%\n  count(size) %&gt;%\n  mutate(percentage = round(n / sum(n) * 100,2))\n\nask_counts &lt;- data %&gt;%\n  count(ask) %&gt;%\n  mutate(percentage = round(n / sum(n) * 100,2))\n\n# Print the result\nprint(ratio_counts)\n\n# A tibble: 4 × 3\n  ratio           n percentage\n  &lt;dbl+lbl&gt;   &lt;int&gt;      &lt;dbl&gt;\n1 0 [Control] 16687       33.3\n2 1           11133       22.2\n3 2           11134       22.2\n4 3           11129       22.2\n\nprint(ask_counts)\n\n# A tibble: 4 × 3\n  ask             n percentage\n  &lt;dbl+lbl&gt;   &lt;int&gt;      &lt;dbl&gt;\n1 0 [Control] 16687       33.3\n2 1 [1x]      11134       22.2\n3 2 [1.25x]   11133       22.2\n4 3 [1.50x]   11129       22.2\n\nprint(size_counts)\n\n# A tibble: 5 × 3\n  size             n percentage\n  &lt;dbl+lbl&gt;    &lt;int&gt;      &lt;dbl&gt;\n1 0 [Control]  16687       33.3\n2 1 [$25,000]   8350       16.7\n3 2 [$50,000]   8345       16.7\n4 3 [$100,000]  8350       16.7\n5 4 [Unstated]  8351       16.7\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\ntodo: test a few variables other than the key outcome variables (for example, test months since last donation) to see if the treatment and control groups are statistically significantly different at the 95% confidence level. Do each as a t-test and separately as a linear regression, and confirm you get the exact same results from both methods. When doing a t-test, use the formula in the class slides. When doing the linear regression, regress for example mrm2 on treatment and look at the estimated coefficient on the treatment variable. It might be helpful to compare parts of your analysis to Table 1 in the paper. Be sure to comment on your results (hint: why is Table 1 included in the paper).\nWe test for a difference in means using both the t-test method and separately the linear regression method. In this case, we use both methods to confirm what we are seeing, however, both methods will ultimately produce the same result. Comparing the means of both the couple and pwhite variables respectively, we see that there is no statistically significant difference between the observations in the treatment and control groups. We tested this hypothesis for each variable at a 95% confidence level. These results give us the confidence to conclude that we do not have the statistical evidence to reject the null hypothesis that there is no difference in the means between the two groups.\n\nComparing Means for couple\n\n#split data into treatment and control\ncontrol_df &lt;- data[data$treatment == 0, ]\ntreatment_df &lt;- data[data$treatment == 1, ]\n\n# create data for ttest\nmean_control &lt;- mean(control_df$couple, na.rm = TRUE)\nsd_control &lt;- sd(control_df$couple, na.rm = TRUE)\nN_control &lt;- length(control_df$couple)\n\nmean_treatment &lt;- mean(treatment_df$couple, na.rm = TRUE)\nsd_treatment &lt;- sd(treatment_df$couple, na.rm = TRUE)\nN_treatment &lt;- length(treatment_df$couple)\n  \n# calculate tstat\nt_stat &lt;- (mean_control - mean_treatment) / sqrt((sd_control^2 / N_control) + (sd_treatment^2 / N_treatment))\nprint(t_stat)\n\n[1] 0.5888429\n\n\n\ncouple_lm &lt;- lm(couple~treatment, data=data)\nsummary(couple_lm)\n\n\nCall:\nlm(formula = couple ~ treatment, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.09297 -0.09297 -0.09136 -0.09136  0.90864 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.092975   0.002261  41.124   &lt;2e-16 ***\ntreatment   -0.001617   0.002770  -0.584    0.559    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2889 on 48933 degrees of freedom\n  (1148 observations deleted due to missingness)\nMultiple R-squared:  6.965e-06, Adjusted R-squared:  -1.347e-05 \nF-statistic: 0.3408 on 1 and 48933 DF,  p-value: 0.5594\n\n\n\n\nComparing Means for pwhite\n\n#split data into treatment and control\ncontrol_df &lt;- data[data$treatment == 0, ]\ntreatment_df &lt;- data[data$treatment == 1, ]\n\n# create data for ttest\nmean_control &lt;- mean(control_df$pwhite, na.rm = TRUE)\nsd_control &lt;- sd(control_df$pwhite, na.rm = TRUE)\nN_control &lt;- length(control_df$pwhite)\n\nmean_treatment &lt;- mean(treatment_df$pwhite, na.rm = TRUE)\nsd_treatment &lt;- sd(treatment_df$pwhite, na.rm = TRUE)\nN_treatment &lt;- length(treatment_df$pwhite)\n  \n# calculate tstat\nt_stat &lt;- (mean_control - mean_treatment) / sqrt((sd_control^2 / N_control) + (sd_treatment^2 / N_treatment))\nprint(t_stat)\n\n[1] 0.570052\n\n\n\n\nLinear Regression for pwhite\n\npwhite_lm &lt;- lm(pwhite~treatment, data=data)\nsummary(pwhite_lm)\n\n\nCall:\nlm(formula = pwhite ~ treatment, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.81079 -0.06378  0.05300  0.11939  0.18070 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.8202078  0.0013309  616.28   &lt;2e-16 ***\ntreatment   -0.0009128  0.0016292   -0.56    0.575    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1686 on 48215 degrees of freedom\n  (1866 observations deleted due to missingness)\nMultiple R-squared:  6.51e-06,  Adjusted R-squared:  -1.423e-05 \nF-statistic: 0.3139 on 1 and 48215 DF,  p-value: 0.5753"
  },
  {
    "objectID": "projects/project1/hw1_questions.html#experimental-results",
    "href": "projects/project1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\ntodo: make a barplot with two bars. Each bar is the proportion of people who donated. One bar for treatment and one bar for control.\nUsing a barplot to visually represen the outcome, we first observe the proportion of people who donated using one bar for treatment and one bar for control. Based on the bar plot below, there is a clear difference in the outcome: the treatement group has a higher proportion of people who donated than the control group. The barplot gives us reason to believe that the treatment may have a causal impact on the outcome of giving. Next, we test this hypothesis using statistical methods.\n\nlibrary(dplyr)\nlibrary(ggplot2)\n\n# Calculating proportions\ndonation_summary &lt;- data %&gt;%\n  group_by(treatment) %&gt;%\n  summarise(proportion_donated = mean(gave))\n\n# Ensure 'treatment' is a factor\ndonation_summary$treatment &lt;- as.factor(donation_summary$treatment)\n\n# Plotting the proportions\nggplot(donation_summary, aes(x = treatment, y = proportion_donated, fill = treatment)) +\n  geom_col() +  \n  scale_fill_manual(values = c(\"blue\", \"red\")) + \n  labs(title = \"Proportion of People Who Donated by Treatment Status\",\n       x = \"Treatment Status\",\n       y = \"Proportion that Donated\") +\n  theme_minimal()  \n\n\n\n\n\n\n\n\ntodo: run a t-test between the treatment and control groups on the binary outcome of whether any charitable donation was made. Also run a bivariate linear regression that demonstrates the same finding. (It may help to confirm your calculations match Table 2a Panel A.) Report your statistical results and interpret them in the context of the experiment (e.g., if you found a difference with a small p-value or that was statistically significant at some threshold, what have you learned about human behavior? Use mostly English words, not numbers or stats, to explain your finding.)\nWe can test our hypothesis by using a t-test to compare the proportions observed between the treatment and control groups. As we have done before, we will confirm the results from our t-test using a bivariate linear regression to demonstrate the same finding.\nThe hypothesis we seek to test is whether or not the proportion of people who gave is the same in both the treatment and the control groups. The result from our t-test is that the treatment group is substantially different from the control group. A large t-stat(t-stat &gt; 2) tells us that we have evidence to suggest that the groups differ and in our case, the t-stat is greater than 3. The results from our bivariate linear regression confirm this finding, adding that being in the treatment group increases the probability of making a charitable donation by 0.004 percent. The third model we use to confirm our results is a probit model. The probit model confirms wht we see in both the t-test as well as the linear regression, allowing us to conclude that we have sufficient statistical evidence to conclude that the treatment has a positive effect on the likelihood of giving.\n\nT-test between the treatment and control groups on the binary outcome of whether any charitable donation was made.\n\n#split data into treatment and control\ncontrol_df &lt;- data[data$treatment == 0, ]\ntreatment_df &lt;- data[data$treatment == 1, ]\n\n# create data for ttest\nmean_control &lt;- mean(control_df$gave, na.rm = TRUE)\nsd_control &lt;- sd(control_df$gave, na.rm = TRUE)\nN_control &lt;- length(control_df$gave)\n\nmean_treatment &lt;- mean(treatment_df$gave, na.rm = TRUE)\nsd_treatment &lt;- sd(treatment_df$gave, na.rm = TRUE)\nN_treatment &lt;- length(treatment_df$gave)\n  \n# calculate tstat\nt_stat &lt;- (mean_control - mean_treatment) / sqrt((sd_control^2 / N_control) + (sd_treatment^2 / N_treatment))\nprint(t_stat)\n\n[1] -3.209462\n\n\n\n\nBi-Variate Linear Regression for whether any charitable donation was made.\n\ngave_lm &lt;- lm(gave~treatment, data=data)\nsummary(gave_lm)\n\n\nCall:\nlm(formula = gave ~ treatment, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.02204 -0.02204 -0.02204 -0.01786  0.98214 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.017858   0.001101  16.225  &lt; 2e-16 ***\ntreatment   0.004180   0.001348   3.101  0.00193 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1422 on 50081 degrees of freedom\nMultiple R-squared:  0.000192,  Adjusted R-squared:  0.0001721 \nF-statistic: 9.618 on 1 and 50081 DF,  p-value: 0.001927\n\n\ntodo: run a probit regression where the outcome variable is whether any charitable donation was made and the explanatory variable is assignment to treatment or control. Confirm that your results replicate Table 3 column 1 in the paper.\n\n# Fit the probit regression model\nprobit &lt;- glm(gave ~ treatment, data = data, family = binomial(link = \"probit\"))\nsummary(probit)\n\n\nCall:\nglm(formula = gave ~ treatment, family = binomial(link = \"probit\"), \n    data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -2.10014    0.02332 -90.074  &lt; 2e-16 ***\ntreatment    0.08678    0.02788   3.113  0.00185 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10061  on 50081  degrees of freedom\nAIC: 10065\n\nNumber of Fisher Scoring iterations: 6\n\n\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\nWe use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. Our results show that the match threshold does not have a statistically significant effect on whether or not people donate. Although this result goes against conventional wisdom, the finding aligns with what was observed in the study.\ntodo: Use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. For example, does the 2:1 match rate lead increase the likelihood that someone donates as compared to the 1:1 match rate? Do your results support the “figures suggest” comment the authors make on page 8?\n\n# Perform a t-test on outcome1\ntest12 &lt;- t.test(gave ~ ratio, data = subset(data, ratio %in% c(1, 2)))\ntest13 &lt;- t.test(gave ~ ratio, data = subset(data, ratio %in% c(1, 3)))\ntest23 &lt;- t.test(gave ~ ratio, data = subset(data, ratio %in% c(2, 3)))\n\n# Print results\nprint(test12)\n\n\n    Welch Two Sample t-test\n\ndata:  gave by ratio\nt = -0.96505, df = 22225, p-value = 0.3345\nalternative hypothesis: true difference in means between group 1 and group 2 is not equal to 0\n95 percent confidence interval:\n -0.005711275  0.001942773\nsample estimates:\nmean in group 1 mean in group 2 \n     0.02074912      0.02263338 \n\nprint(test13)\n\n\n    Welch Two Sample t-test\n\ndata:  gave by ratio\nt = -1.015, df = 22215, p-value = 0.3101\nalternative hypothesis: true difference in means between group 1 and group 3 is not equal to 0\n95 percent confidence interval:\n -0.005816051  0.001847501\nsample estimates:\nmean in group 1 mean in group 3 \n     0.02074912      0.02273340 \n\nprint(test23)\n\n\n    Welch Two Sample t-test\n\ndata:  gave by ratio\nt = -0.050116, df = 22261, p-value = 0.96\nalternative hypothesis: true difference in means between group 2 and group 3 is not equal to 0\n95 percent confidence interval:\n -0.004012044  0.003811996\nsample estimates:\nmean in group 2 mean in group 3 \n     0.02263338      0.02273340 \n\n\ntodo: Assess the same issue using a regression. Specifically, create the variable ratio1 then regress gave on ratio1, ratio2, and ratio3 (or alternatively, regress gave on the categorical variable ratio). Interpret the coefficients and their statistical precision.\nTo test the claim that the match threshold has no significant impact on whether or not someone decides to give, we execute a logistic regression, regressing gave on ratio1, ratio2, and ratio3. This test will tell us how each ratio effects the odds of someone giving anything. The coefficient for ratio 1 is positive but not statistically significant, meaning that the effect of the 1:1 ratio is not statistically significant from the effect observed when no match is offered. The effect of ratio’s 2 and 3 are both positive and statistically significant. Notably, their coefficients are nearly exactly the same, which shows tht the difference between a 2:1 ratio and a 3:1 ratio is essentially the same.\n\n# Create 'ratio1' \ndata &lt;- data %&gt;%\n  mutate(ratio1 = as.integer(ratio == 1))\n\n# Fit a logistic regression model\nmodel &lt;- glm(gave ~ ratio1 + ratio2 + ratio3, family = binomial(), data = data)\n\n# Summary of the model\nsummary(model)\n\n\nCall:\nglm(formula = gave ~ ratio1 + ratio2 + ratio3, family = binomial(), \n    data = data)\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -4.00727    0.05844 -68.565  &lt; 2e-16 ***\nratio1       0.15299    0.08852   1.728  0.08394 .  \nratio2       0.24184    0.08646   2.797  0.00516 ** \nratio3       0.24635    0.08637   2.852  0.00434 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 10071  on 50082  degrees of freedom\nResidual deviance: 10060  on 50079  degrees of freedom\nAIC: 10068\n\nNumber of Fisher Scoring iterations: 6\n\n\ntodo: Calculate the response rate difference between the 1:1 and 2:1 match ratios and the 2:1 and 3:1 ratios. Do this directly from the data, and do it by computing the differences in the fitted coefficients of the previous regression. what do you conclude regarding the effectiveness of different sizes of matched donations?\n\n# create data subsets\nratio1_data &lt;- data[data$ratio == 1, ]\nratio2_data &lt;- data[data$ratio == 2, ]\nratio3_data &lt;- data[data$ratio == 3, ]\n\n# Calculate the mean of 'gave' for the subsets\nratio1_rr &lt;- mean(ratio1_data$gave, na.rm = TRUE) \nratio2_rr &lt;- mean(ratio2_data$gave, na.rm = TRUE) \nratio3_rr &lt;- mean(ratio3_data$gave, na.rm = TRUE) \n\nprint(ratio1_rr)\n\n[1] 0.02074912\n\nprint(ratio2_rr)\n\n[1] 0.02263338\n\nprint(ratio3_rr)\n\n[1] 0.0227334\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis? To measure the effect we run a bivariate linear regression of the donation amount on the treatment status. In the summary of this regression, we see that being in the treatment group has a positive effect on the size of the matched donation that is statistically significant at the 90 percent level.\n\namount_lm &lt;- lm(amount~treatment, data=data)\nsummary(amount_lm)\n\n\nCall:\nlm(formula = amount ~ treatment, data = data)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n -0.97  -0.97  -0.97  -0.81 399.03 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.81327    0.06742  12.063   &lt;2e-16 ***\ntreatment    0.15361    0.08256   1.861   0.0628 .  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.709 on 50081 degrees of freedom\nMultiple R-squared:  6.911e-05, Adjusted R-squared:  4.915e-05 \nF-statistic: 3.461 on 1 and 50081 DF,  p-value: 0.06282\n\n\ntodo: now limit the data to just people who made a donation and repeat the previous analysis. This regression allows you to analyze how much respondents donate conditional on donating some positive amount. Interpret the regression coefficients – what did we learn? Does the treatment coefficient have a causal interpretation?\nRepeating the analysis above using only the data from people who made a contribution, we are able to measure how much respondents donate conditional on donating some positive amount. In this case, we see that being in the treatment group has a negative impact, however, this impact is not statistically significant. This tells us that we are unsure whether the treatment is actually effecting the amount that people decide to give. Becuase our treatment coefficient is insignificant, we cannot conclude that the treatment has any effect on the amount that people decide to give. For this reason, we conclude that we do not have sufficient evidence to state that the treatment has a causal effect on the outcome.\n\ngivers_only &lt;- data[data$amount &gt; 0, ]\namount_lm &lt;- lm(amount~treatment, data=givers_only)\nsummary(amount_lm)\n\n\nCall:\nlm(formula = amount ~ treatment, data = givers_only)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-43.54 -23.87 -18.87   6.13 356.13 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   45.540      2.423  18.792   &lt;2e-16 ***\ntreatment     -1.668      2.872  -0.581    0.561    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 41.83 on 1032 degrees of freedom\nMultiple R-squared:  0.0003268, Adjusted R-squared:  -0.0006419 \nF-statistic: 0.3374 on 1 and 1032 DF,  p-value: 0.5615\n\n\ntodo: Make two plot: one for the treatment group and one for the control. Each plot should be a histogram of the donation amounts only among people who donated. Add a red vertical bar or some other annotation to indicate the sample average for each plot.\n\n# control group givers\ngivers_control &lt;- control_df[control_df$amount &gt; 0, ]\n\n# Calculate the mean of the donation amounts\nmean_amount &lt;- mean(givers_control$amount)\n\n# Creating the histogram with a vertical line indicating the mean\nhistogram1 &lt;- ggplot(givers_control, aes(x = amount)) +\n  geom_histogram(binwidth = 10, fill = \"blue\", color = \"black\") +  # Histogram\n  geom_vline(aes(xintercept = mean_amount), color = \"red\", linetype = \"dashed\", size = 1) +  # Mean line\n  labs(title = \"Donation Amounts (Control Group)\",\n       x = \"Donation Amount\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  ggtitle(paste(\"Control Group Donation Amounts with Mean at $\", round(mean_amount, 2)))\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n# Print the histogram\nprint(histogram1)\n\n\n\n\n\n\n\n\n\n# treatment group givers\ngivers_treatment &lt;- treatment_df[treatment_df$amount &gt; 0, ]\n\n# Calculate the mean of the donation amounts\nmean_amount &lt;- mean(givers_treatment$amount)\n\n# Creating the histogram with a vertical line indicating the mean\nhistogram1 &lt;- ggplot(givers_treatment, aes(x = amount)) +\n  geom_histogram(binwidth = 10, fill = \"blue\", color = \"black\") +  # Histogram\n  geom_vline(aes(xintercept = mean_amount), color = \"red\", linetype = \"dashed\", size = 1) +  # Mean line\n  labs(title = \"Donation Amounts (Treatment Group)\",\n       x = \"Donation Amount\",\n       y = \"Frequency\") +\n  theme_minimal() +\n  ggtitle(paste(\"Treatment Group Donation Amounts with Mean at $\", round(mean_amount, 2)))\n\n# Print the histogram\nprint(histogram1)"
  },
  {
    "objectID": "projects/project1/hw1_questions.html#simulation-experiment",
    "href": "projects/project1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\nThis first plot is a demonstration of the Law of Large Numbers. This law states that as your sample size increases, you can expect your sample average to get closer to the true mean. To recreate this, we first simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. Next, we calculate a vector of 10,000 differences and then plot the cumulative average of that vector of differences. The plot shows that as we increase our sample size, the sample mean gets closer to the true mean. In our case, the sample mean never actually approaches the true difference in means. One simple way to fix this would be to increase our sample size beyond 10,000. to do: Make a plot like those on slide 43 from our first class and explain the plot to the reader. To do this, you will simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. You’ll then calculate a vector of 10,000 differences, and then you’ll plot the cumulative average of that vector of differences. Comment on whether the cumulative average approaches the true difference in means.\n\n# number of simulations\nn &lt;- 10000\n\n# probability of success\np_c &lt;- 0.018\np_t &lt;- 0.022\n\n# True mean difference\ntrue_diff &lt;- p_t - p_c\n\n# simulated draws\nset.seed(10)\ncontrol_sim &lt;- rbinom(n,size = 1, prob = p_c)\ntreatment_sim &lt;- rbinom(n,size = 1, prob = p_t)\n\n# Calculate cumulative means for both simulations\ncummean_control &lt;- cumsum(control_sim) / (1:n)\ncummean_treatment &lt;- cumsum(treatment_sim) / (1:n)\n\n# Calculate the cumulative differences\nsample_cumdiff &lt;- cummean_treatment - cummean_control\n\n# Create a data frame for plotting\nplot_data &lt;- data.frame(\n  Simulation = 1:n,\n  CumulativeDifference = sample_cumdiff\n)\n\n\n# Generate the plot\nggplot(plot_data, aes(x = Simulation, y = CumulativeDifference)) +\n  geom_line(color = \"red\") + \n  geom_hline(yintercept = true_diff, linetype = \"dashed\", color = \"blue\") + \n  labs(title = \"Cumulative Difference Between Treatment and Control\",\n       x = \"Number of Simulations\",\n       y = \"Cumulative Difference\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nCentral Limit Theorem\nto do: Make 4 histograms like those on slide 44 from our first class at sample sizes 50, 200, 500, and 1000 and explain these plots to the reader. To do this for a sample size of e.g. 50, take 50 draws from each of the control and treatment distributions, and calculate the average difference between those draws. Then repeat that process 999 more times so that you have 1000 averages. Plot the histogram of those averages. Comment on whether zero is in the “middle” of the distribution or whether it’s in the “tail.” To demonstrate the Central Limit Theorem we create histograms showing us the average difference between the treatment and control group from simulations of different sample sizes. The sample sizes we tested are 50, 200, 500, and 1000. As you can see in the plots, there are less observations in the tails of the data as the sample size increases. This observation validates the Central Limit Theorem because it shows that as we increase sample size the sample statistic gets closer to the true value. It is also worth noting that the value zero is in the middle of the distribution in each histogram.\n\n# Number of repetitions\nreps &lt;- 1000\n\n# Different numbers of draws\ndraw_sizes &lt;- c(50, 200, 500, 1000)\n\n# Probabilities for control and treatment groups\np_c &lt;- 0.018\np_t &lt;- 0.022\n\n# Set a seed for reproducibility\nset.seed(10)\n\n# Loop over each draw size\nfor (draws in draw_sizes) {\n    # Initialize a vector to store the average differences for the current draw size\n    mean_diff &lt;- numeric(reps)\n    \n    # Repeat draw and calculation for the current number of draws\n    for (i in 1:reps) {\n        # Simulate draws from Bernoulli distributions for control and treatment\n        c_sim &lt;- rbinom(draws, size = 1, prob = p_c)\n        t_sim &lt;- rbinom(draws, size = 1, prob = p_t)\n    \n        # Calculate the average difference and store it\n        mean_diff[i] &lt;- mean(t_sim) - mean(c_sim)\n    }\n    \n    # Visualize the distribution of average differences for the current draw size\n    plot_data &lt;- data.frame(AverageDifferences = mean_diff)\n    p &lt;- ggplot(plot_data, aes(x = AverageDifferences)) +\n        geom_histogram(bins = 30, fill = \"dodgerblue\", color = \"black\") +\n        labs(title = paste(\"Histogram of Average Differences for\", draws, \"Draws\"),\n             x = \"Average Difference\",\n             y = \"Frequency\") +\n        theme_minimal()\n    \n    print(p)  # Display the plot\n}"
  }
]