---
title: "Poisson Regression Examples"
author: "Warren Kennedy"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
editor_options: 
  chunk_output_type: console
---

This assignment uses uses the MNL model to analyze (1) yogurt purchase data made by consumers at a retail location, and (2) conjoint data about consumer preferences for minivans.

## 1. Estimating Yogurt Preferences

### Likelihood for the Multi-nomial Logit (MNL) Model

Suppose we have $i=1,\ldots,n$ consumers who each select exactly one product $j$ from a set of $J$ products. The outcome variable is the identity of the product chosen $y_i \in \{1, \ldots, J\}$ or equivalently a vector of $J-1$ zeros and $1$ one, where the $1$ indicates the selected product. For example, if the third product was chosen out of 4 products, then either $y=3$ or $y=(0,0,1,0)$ depending on how we want to represent it. Suppose also that we have a vector of data on each product $x_j$ (eg, size, price, etc.).

We model the consumer's decision as the selection of the product that provides the most utility, and we'll specify the utility function as a linear function of the product characteristics:

$$ U_{ij} = x_j'\beta + \epsilon_{ij} $$

where $\epsilon_{ij}$ is an i.i.d. extreme value error term.

The choice of the i.i.d. extreme value error term leads to a closed-form expression for the probability that consumer $i$ chooses product $j$:

$$ \mathbb{P}_i(j) = \frac{e^{x_j'\beta}}{\sum_{k=1}^Je^{x_k'\beta}} $$

For example, if there are 4 products, the probability that consumer $i$ chooses product 3 is:

$$ \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{e^{x_1'\beta} + e^{x_2'\beta} + e^{x_3'\beta} + e^{x_4'\beta}} $$

A clever way to write the individual likelihood function for consumer $i$ is the product of the $J$ probabilities, each raised to the power of an indicator variable ($\delta_{ij}$) that indicates the chosen product:

$$ L_i(\beta) = \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} = \mathbb{P}_i(1)^{\delta_{i1}} \times \ldots \times \mathbb{P}_i(J)^{\delta_{iJ}}$$

Notice that if the consumer selected product $j=3$, then $\delta_{i3}=1$ while $\delta_{i1}=\delta_{i2}=\delta_{i4}=0$ and the likelihood is:

$$ L_i(\beta) = \mathbb{P}_i(1)^0 \times \mathbb{P}_i(2)^0 \times \mathbb{P}_i(3)^1 \times \mathbb{P}_i(4)^0 = \mathbb{P}_i(3) = \frac{e^{x_3'\beta}}{\sum_{k=1}^Je^{x_k'\beta}} $$

The joint likelihood (across all consumers) is the product of the $n$ individual likelihoods:

$$ L_n(\beta) = \prod_{i=1}^n L_i(\beta) = \prod_{i=1}^n \prod_{j=1}^J \mathbb{P}_i(j)^{\delta_{ij}} $$

And the joint log-likelihood function is:

$$ \ell_n(\beta) = \sum_{i=1}^n \sum_{j=1}^J \delta_{ij} \log(\mathbb{P}_i(j)) $$

### Yogurt Dataset

We will use the `yogurt_data` dataset, which provides anonymized consumer identifiers (`id`), a vector indicating the chosen product (`y1`:`y4`), a vector indicating if any products were "featured" in the store as a form of advertising (`f1`:`f4`), and the products' prices (`p1`:`p4`). For example, consumer 1 purchased yogurt 4 at a price of 0.079/oz and none of the yogurts were featured/advertised at the time of consumer 1's purchase. Consumers 2 through 7 each bought yogurt 2, etc.

*todo: import the data, maybe show the first few rows, and describe the data a bit.*

To begin our analysis, we examine the dataset to identify any noticeable trends. The bar plot below illustrates several key observations.

Firstly, in terms of product selection frequency, each product demonstrates distinct levels of popularity. Product 2 was chosen most frequently, with 975 selections, followed by product 1 with 831 selections, product 4 with 553 selections, and notably, product 3 with only 71 selections.

Secondly, regarding product the frequency of each product being featured, products 2, 3, and 4 were featured approximately 90 times each, while product 1 stood out with 135 features. These initial observations provide valuable insights into the relative popularity and feature exposure of each product, setting the stage for further in-depth analysis. 
```{r}
yogurt_data <- read.csv("~/My_Quarto_Website/projects/project3/yogurt_data.csv", header=TRUE)
head(yogurt_data)

# frequency of product being chosen
P1_chosen <- sum(yogurt_data$y1 == 1)
P2_chosen <- sum(yogurt_data$y2 == 1)
P3_chosen <- sum(yogurt_data$y3 == 1)
P4_chosen <- sum(yogurt_data$y4 == 1)

choice_counts <- c(P1_chosen, P2_chosen, P3_chosen, P4_chosen)

# frequency of product being featured
P1_featured <- sum(yogurt_data$f1 == 1)
P2_featured <- sum(yogurt_data$f2 == 1)
P3_featured <- sum(yogurt_data$f3 == 1)
P4_featured <- sum(yogurt_data$f4 == 1)

feature_counts <- c(P1_featured, P2_featured, P3_featured, P4_featured)


# Plotting choice and feature frequency
par(mfrow=c(1,1))
combined_counts <- rbind(choice_counts, feature_counts)
barplot(combined_counts, beside=TRUE, names.arg=c("Product 1", "Product 2", "Product 3", "Product 4"),
        xlab="Product", ylab="Frequency", main="Distribution of Products Chosen and Featured",
        col=c("blue", "red"), legend=c("Chosen", "Featured"))
```


Lastly, we observe the distribution of price per ounce charged for each product. The frequency plots for each product reveal distinct pricing patterns. Products 1, 2, and 4 exhibit a narrow distribution, with a common price point that dominates their sales. In contrast, product 3 displays a broader distribution, indicating multiple price points at which it is frequently sold. Despite this variability, product 3 was sold less frequently compared to the other products.


```{r}
# Load the dplyr package
library(dplyr)

# Assuming 'yogurt_data' is the name of your dataframe
# Create a copy of the dataframe
yogurt_data_copy <- data.frame(yogurt_data)

# Convert to numeric
yogurt_data_copy$p1 <- as.numeric(yogurt_data_copy$p1)
yogurt_data_copy$p2 <- as.numeric(yogurt_data_copy$p2)
yogurt_data_copy$p3 <- as.numeric(yogurt_data_copy$p3)
yogurt_data_copy$p4 <- as.numeric(yogurt_data_copy$p4)

# Plot a histogram
hist(yogurt_data_copy$p1, main = "Histogram of Price for Product 1", xlab = "Price", ylab = "Frequency")
hist(yogurt_data_copy$p2, main = "Histogram of Price for Product 2", xlab = "Price", ylab = "Frequency")
hist(yogurt_data_copy$p3, main = "Histogram of Price for Product 3", xlab = "Price", ylab = "Frequency")
hist(yogurt_data_copy$p4, main = "Histogram of Price for Product 4", xlab = "Price", ylab = "Frequency")

```


Let the vector of product features include brand dummy variables for yogurts 1-3 (we'll omit a dummy for product 4 to avoid multi-collinearity), a dummy variable to indicate if a yogurt was featured, and a continuous variable for the yogurts' prices:

$$ x_j' = [\mathbbm{1}(\text{Yogurt 1}), \mathbbm{1}(\text{Yogurt 2}), \mathbbm{1}(\text{Yogurt 3}), X_f, X_p] $$

The "hard part" of the MNL likelihood function is organizing the data, as we need to keep track of 3 dimensions (consumer $i$, covariate $k$, and product $j$) instead of the typical 2 dimensions for cross-sectional regression models (consumer $i$ and covariate $k$).

What we would like to do is reorganize the data from a "wide" shape with $n$ rows and multiple columns for each covariate, to a "long" shape with $n \times J$ rows and a single column for each covariate. As part of this re-organization, we'll add binary variables to indicate the first 3 products; the variables for featured and price are included in the dataset and simply need to be "pivoted" or "melted" from wide to long.

*todo: reshape and prep the data*
```{r}
library(dplyr)
library(tidyr)

# Assuming your wide-format dataframe is named 'wide_data'
# Select columns to keep
yogurt_subset <- yogurt_data %>%
  select(id, starts_with("f"), starts_with("p"), -f4, -p4)

# Melt the data into long format
yogurt_long <- pivot_longer(yogurt_subset, 
                          cols = starts_with("f") | starts_with("p"),
                          names_to = c(".value", "product"),
                          names_sep = "")

# View the long-format dataframe
print(yogurt_long)

```


### Estimation

*todo: Code up the log-likelihood function.*

*todo: Use `optim()` in R or `optimize()` in Python to find the MLEs for the 5 parameters (*$\beta_1, \beta_2, \beta_3, \beta_f, \beta_p$). (Hint: you should find 2 positive and 1 negative product intercepts, a small positive coefficient estimate for featured, and a large negative coefficient estimate for price.)

### Discussion

We learn...

*todo: interpret the 3 product intercepts (which yogurt is most preferred?).*

*todo: use the estimated price coefficient as a dollar-per-util conversion factor. Use this conversion factor to calculate the dollar benefit between the most-preferred yogurt (the one with the highest intercept) and the least preferred yogurt (the one with the lowest intercept). This is a per-unit monetary measure of brand value.*

One benefit of the MNL model is that we can simulate counterfactuals (eg, what if the price of yogurt 1 was \$0.10/oz instead of \$0.08/oz).

*todo: calculate the market shares in the market at the time the data were collected. Then, increase the price of yogurt 1 by \$0.10 and use your fitted model to predict p(y\|x) for each consumer and each product (this should be a matrix of* $N \times 4$ estimated choice probabilities. Take the column averages to get the new, expected market shares that result from the \$0.10 price increase to yogurt 1. Do the yogurt 1 market shares decrease?

## 2. Estimating Minivan Preferences

### Data

*todo: download the dataset from here:* http://goo.gl/5xQObB

*todo: describe the data a bit. How many respondents took the conjoint survey? How many choice tasks did each respondent complete? How many alternatives were presented on each choice task? For each alternative.*

The attributes (levels) were number of seats (6,7,8), cargo space (2ft, 3ft), engine type (gas, hybrid, electric), and price (in thousands of dollars).

### Model

*todo: estimate a MNL model omitting the following levels to avoide multicollinearity (6 seats, 2ft cargo, and gas engine). Include price as a continuous variable. Show a table of coefficients and standard errors. You may use your own likelihood function from above, or you may use a function from a package/library to perform the estimation.*

### Results

*todo: Interpret the coefficients. Which features are more preferred?*

*todo: Use the price coefficient as a dollar-per-util conversion factor. What is the dollar value of 3ft of cargo space as compared to 2ft of cargo space?*

*todo: assume the market consists of the following 6 minivans. Predict the market shares of each minivan in the market.*

| Minivan | Seats | Cargo | Engine | Price |
|---------|-------|-------|--------|-------|
| A       | 7     | 2     | Hyb    | 30    |
| B       | 6     | 2     | Gas    | 30    |
| C       | 8     | 2     | Gas    | 30    |
| D       | 7     | 3     | Gas    | 40    |
| E       | 6     | 2     | Elec   | 40    |
| F       | 7     | 2     | Hyb    | 35    |

*hint: this example is taken from the "R 4 Marketing Research" book by Chapman and Feit. I believe the same example is present in the companion book titled "Python 4 Marketing Research". I encourage you to attempt these questions on your own, but if you get stuck or would like to compare you results to "the answers," you may consult the Chapman and Feit books.*
