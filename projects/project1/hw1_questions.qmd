---
title: "A Replication of Karlan and List (2007)"
author: "Warren Kennedy"
date: today
callout-appearance: minimal # this hides the blue "i" icon on .callout-notes
---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).


The experiment tests a variety of hypotheses, including whether matching donations increases the likelihood of a donation, whether the size of the match matters, and whether the size of the donation is affected by the match. To accomplish this, the authors used a variety of treatments, varying the price ratios for the match, the maximum matching grant amount, and the individual-specific ask amount. The treatments were letters used to solicit donations for a liberal politically motivated group that were sent to all 50 states. To control for spatial heterogeneity, the authors made sure that the treatment and control groups were balanced across states using demographic data, state and county election data, and data on the organization's activity level within each state. Ultimately, the authors find that matching donations increases the likelihood of a donation, however, they also find that the size of the match does not matter, and that the size of the donation is not affected by the match. 

This project seeks to replicate their results.


## Data

### Description

 
```{r}
# read the data 
library(haven)
data <- read_dta("/home/jovyan/My_Quarto_Website/projects/project1/karlan_list_2007.dta")

# summarize treatment/control split
treatment_perc <- mean(data$treatment)
control_perc <-mean(data$control)

# Print the result
print(treatment_perc)
print(control_perc)
```

```{r}
# Create tables to show the distributions of the treatment features
library(dplyr)
ratio_counts <- data %>%
  count(ratio) %>%
  mutate(percentage = round(n / sum(n) * 100,2))

size_counts <- data %>%
  count(size) %>%
  mutate(percentage = round(n / sum(n) * 100,2))

ask_counts <- data %>%
  count(ask) %>%
  mutate(percentage = round(n / sum(n) * 100,2))

# Print the result
print(ratio_counts)
print(ask_counts)
print(size_counts)

```


:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::


### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

We test for a difference in means using both the t-test method and separately the linear regression method. In this case, we use both methods to confirm what we are seeing, however, both methods will ultimately produce the same result. Comparing the means of both the `couple` and `pwhite` variables respectively, we see that there is no statistically significant difference between the observations in the treatment and control groups. We tested this hypothesis for each variable at a 95% confidence level. These results give us the confidence to conclude that we do not have the statistical evidence to reject the null hypothesis that there is no difference in the means between the two groups.

#### Comparing Means for `couple`
```{r}
#split data into treatment and control
control_df <- data[data$treatment == 0, ]
treatment_df <- data[data$treatment == 1, ]

# create data for ttest
mean_control <- mean(control_df$couple, na.rm = TRUE)
sd_control <- sd(control_df$couple, na.rm = TRUE)
N_control <- length(control_df$couple)

mean_treatment <- mean(treatment_df$couple, na.rm = TRUE)
sd_treatment <- sd(treatment_df$couple, na.rm = TRUE)
N_treatment <- length(treatment_df$couple)
  
# calculate tstat
t_stat <- (mean_control - mean_treatment) / sqrt((sd_control^2 / N_control) + (sd_treatment^2 / N_treatment))
print(t_stat)
```
```{r}
couple_lm <- lm(couple~treatment, data=data)
summary(couple_lm)
```

#### Comparing Means for `pwhite`
```{r}
#split data into treatment and control
control_df <- data[data$treatment == 0, ]
treatment_df <- data[data$treatment == 1, ]

# create data for ttest
mean_control <- mean(control_df$pwhite, na.rm = TRUE)
sd_control <- sd(control_df$pwhite, na.rm = TRUE)
N_control <- length(control_df$pwhite)

mean_treatment <- mean(treatment_df$pwhite, na.rm = TRUE)
sd_treatment <- sd(treatment_df$pwhite, na.rm = TRUE)
N_treatment <- length(treatment_df$pwhite)
  
# calculate tstat
t_stat <- (mean_control - mean_treatment) / sqrt((sd_control^2 / N_control) + (sd_treatment^2 / N_treatment))
print(t_stat)
```
#### Linear Regression for `pwhite`
```{r}
pwhite_lm <- lm(pwhite~treatment, data=data)
summary(pwhite_lm)
```


## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

Using a barplot to visually represen the outcome, we first observe the proportion of people who donated using one bar for treatment and one bar for control. Based on the bar plot below, there is a clear difference in the outcome: the treatement group has a higher proportion of people who donated than the control group. The barplot gives us reason to believe that the treatment may have a causal impact on the outcome of giving. Next, we test this hypothesis using statistical methods. 
```{r}
library(dplyr)
library(ggplot2)

# Calculating proportions
donation_summary <- data %>%
  group_by(treatment) %>%
  summarise(proportion_donated = mean(gave))

# Ensure 'treatment' is a factor
donation_summary$treatment <- as.factor(donation_summary$treatment)

# Plotting the proportions
ggplot(donation_summary, aes(x = treatment, y = proportion_donated, fill = treatment)) +
  geom_col() +  
  scale_fill_manual(values = c("blue", "red")) + 
  labs(title = "Proportion of People Who Donated by Treatment Status",
       x = "Treatment Status",
       y = "Proportion that Donated") +
  theme_minimal()  

```


We can test our hypothesis by using a t-test to compare the proportions observed between the treatment and control groups. As we have done before, we will confirm the results from our t-test using a bivariate linear regression to demonstrate the same finding. 

The hypothesis we seek to test is whether or not the proportion of people who gave is the same in both the treatment and the control groups. The result from our t-test is that the treatment group is substantially different from the control group. A large t-stat(t-stat > 2) tells us that we have evidence to suggest that the groups differ and in our case, the t-stat is greater than 3. The results from our bivariate linear regression confirm this finding, adding that being in the treatment group increases the probability of making a charitable donation by 0.004 percent. The third model we use to confirm our results is a probit model. The probit model confirms wht we see in both the t-test as well as the linear regression, allowing us to conclude that we have sufficient statistical evidence to conclude that the treatment has a positive effect on the likelihood of giving.

#### T-test between the treatment and control groups on the binary outcome of whether any charitable donation was made.
```{r}
#split data into treatment and control
control_df <- data[data$treatment == 0, ]
treatment_df <- data[data$treatment == 1, ]

# create data for ttest
mean_control <- mean(control_df$gave, na.rm = TRUE)
sd_control <- sd(control_df$gave, na.rm = TRUE)
N_control <- length(control_df$gave)

mean_treatment <- mean(treatment_df$gave, na.rm = TRUE)
sd_treatment <- sd(treatment_df$gave, na.rm = TRUE)
N_treatment <- length(treatment_df$gave)
  
# calculate tstat
t_stat <- (mean_control - mean_treatment) / sqrt((sd_control^2 / N_control) + (sd_treatment^2 / N_treatment))
print(t_stat)
```

#### Bi-Variate Linear Regression for whether any charitable donation was made.
```{r}
gave_lm <- lm(gave~treatment, data=data)
summary(gave_lm)
```


```{r}
# Fit the probit regression model
probit <- glm(gave ~ treatment, data = data, family = binomial(link = "probit"))
summary(probit)

```


### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.

We use a series of t-tests to test whether the size of the match ratio has an effect on whether people donate or not. Our results show that the match threshold does not have a statistically significant effect on whether or not people donate. Although this result goes against conventional wisdom, the finding aligns with what was observed in the study.

```{r}
# Perform a t-test on outcome1
test12 <- t.test(gave ~ ratio, data = subset(data, ratio %in% c(1, 2)))
test13 <- t.test(gave ~ ratio, data = subset(data, ratio %in% c(1, 3)))
test23 <- t.test(gave ~ ratio, data = subset(data, ratio %in% c(2, 3)))

# Print results
print(test12)
print(test13)
print(test23)

```

To test the claim that the match threshold has no significant impact on whether or not someone decides to give, we execute a logistic regression, regressing `gave` on `ratio1`, `ratio2`, and `ratio3`. This test will tell us how each ratio effects the odds of someone giving anything. The coefficient for ratio 1 is positive but not statistically significant, meaning that the effect of the 1:1 ratio is not statistically significant from the effect observed when no match is offered. The effect of ratio's 2 and 3 are both positive and statistically significant. Notably, their coefficients are nearly exactly the same, which shows that the difference between a 2:1 ratio and a 3:1 ratio is essentially the same.
```{r}
# Create 'ratio1' 
data <- data %>%
  mutate(ratio1 = as.integer(ratio == 1))

# Fit a logistic regression model
model <- lm(gave ~ ratio1 + ratio2 + ratio3, data = data)

# Summary of the model
summary(model)
```


```{r}
# create data subsets
ratio1_data <- data[data$ratio == 1, ]
ratio2_data <- data[data$ratio == 2, ]
ratio3_data <- data[data$ratio == 3, ]

# Calculate the mean of 'gave' for the subsets
ratio1_rr <- mean(ratio1_data$gave, na.rm = TRUE) 
ratio2_rr <- mean(ratio2_data$gave, na.rm = TRUE) 
ratio3_rr <- mean(ratio3_data$gave, na.rm = TRUE) 

print(ratio1_rr)
print(ratio2_rr)
print(ratio3_rr)
```


### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.

```{r}
amount_lm <- lm(amount~treatment, data=data)
summary(amount_lm)
```


Repeating the analysis above using only the data from people who made a contribution, we are able to measure how much respondents donate conditional on donating some positive amount. In this case, we see that being in the treatment group has a negative impact, however, this impact is not statistically significant. This tells us that we are unsure whether the treatment is actually effecting the amount that people decide to give. Becuase our treatment coefficient is insignificant, we cannot conclude that the treatment has any effect on the amount that people decide to give. For this reason, we conclude that we do not have sufficient evidence to state that  the treatment has a causal effect on the outcome.
```{r}
givers_only <- data[data$amount > 0, ]
amount_lm <- lm(amount~treatment, data=givers_only)
summary(amount_lm)
```

```{r}
# control group givers
givers_control <- control_df[control_df$amount > 0, ]

# Calculate the mean of the donation amounts
mean_amount <- mean(givers_control$amount)

# Creating the histogram with a vertical line indicating the mean
histogram1 <- ggplot(givers_control, aes(x = amount)) +
  geom_histogram(binwidth = 10, fill = "blue", color = "black") +  # Histogram
  geom_vline(aes(xintercept = mean_amount), color = "red", linetype = "dashed", size = 1) +  # Mean line
  labs(title = "Donation Amounts (Control Group)",
       x = "Donation Amount",
       y = "Frequency") +
  theme_minimal() +
  ggtitle(paste("Control Group Donation Amounts with Mean at $", round(mean_amount, 2)))

# Print the histogram
print(histogram1)

```
```{r}
# treatment group givers
givers_treatment <- treatment_df[treatment_df$amount > 0, ]

# Calculate the mean of the donation amounts
mean_amount <- mean(givers_treatment$amount)

# Creating the histogram with a vertical line indicating the mean
histogram1 <- ggplot(givers_treatment, aes(x = amount)) +
  geom_histogram(binwidth = 10, fill = "blue", color = "black") +  # Histogram
  geom_vline(aes(xintercept = mean_amount), color = "red", linetype = "dashed", size = 1) +  # Mean line
  labs(title = "Donation Amounts (Treatment Group)",
       x = "Donation Amount",
       y = "Frequency") +
  theme_minimal() +
  ggtitle(paste("Treatment Group Donation Amounts with Mean at $", round(mean_amount, 2)))

# Print the histogram
print(histogram1)

```

## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who **do not get a charitable donation match** is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who **do get a charitable donation match** of any size  is Bernoulli with probability p=0.022 that a donation is made.

### Law of Large Numbers

This first plot is a demonstration of the Law of Large Numbers. This law states that as your sample size increases, you can expect your sample average to get closer to the true mean. To recreate this, we first simulate 10,000 draws from the control distribution and 10,000 draws from the treatment distribution. Next, we calculate a vector of 10,000 differences and then plot the cumulative average of that vector of differences. The plot shows that as we increase our sample size, the sample mean gets closer to the true mean. In our case, the sample mean never actually approaches the true difference in means. One simple way to fix this would be to increase our sample size beyond 10,000. 

```{r}
# number of simulations
n <- 10000

# probability of success
p_c <- 0.018
p_t <- 0.022

# True mean difference
true_diff <- p_t - p_c

# simulated n draws for treatment and control
set.seed(10)
control_sim <- rbinom(n,size = 1, prob = p_c)
treatment_sim <- rbinom(n,size = 1, prob = p_t)

# Calculate cumulative means for both simulations
cummean_control <- cumsum(control_sim) / (1:n)
cummean_treatment <- cumsum(treatment_sim) / (1:n)

# Calculate the cumulative differences
sample_cumdiff <- cummean_treatment - cummean_control

# Create a data frame for plotting
plot_data <- data.frame(
  Simulation = 1:n,
  CumulativeDifference = sample_cumdiff
)


# Generate the plot
ggplot(plot_data, aes(x = Simulation, y = CumulativeDifference)) +
  geom_line(color = "red") + 
  geom_hline(yintercept = true_diff, linetype = "dashed", color = "blue") + 
  labs(title = "Cumulative Difference Between Treatment and Control",
       x = "Number of Simulations",
       y = "Cumulative Difference") +
  theme_minimal()
```


### Central Limit Theorem

To demonstrate the Central Limit Theorem we create histograms showing us the average difference between the treatment and control group from simulations of different sample sizes. The sample sizes we tested are 50, 200, 500, and 1000. As you can see in the plots, there are less observations in the tails of the data as the sample size increases. This observation validates the Central Limit Theorem because it shows that as we increase sample size the sample statistic gets closer to the true value. It is also worth noting that the value zero is in the middle of the distribution in each histogram. 
```{r}
# Number of repetitions
reps <- 1000

# Different numbers of draws
draw_sizes <- c(50, 200, 500, 1000)

# Probabilities for control and treatment groups
p_c <- 0.018
p_t <- 0.022

# Set a seed for reproducibility
set.seed(10)

# Loop over each draw size
for (draws in draw_sizes) {
    # Initialize a vector to store the average differences for the current draw size
    mean_diff <- numeric(reps)
    
    # Repeat draw and calculation for the current number of draws
    for (i in 1:reps) {
        # Simulate draws from Bernoulli distributions for control and treatment
        c_sim <- rbinom(draws, size = 1, prob = p_c)
        t_sim <- rbinom(draws, size = 1, prob = p_t)
    
        # Calculate the average difference and store it
        mean_diff[i] <- mean(t_sim) - mean(c_sim)
    }
    
    # Visualize the distribution of average differences for the current draw size
    plot_data <- data.frame(AverageDifferences = mean_diff)
    p <- ggplot(plot_data, aes(x = AverageDifferences)) +
        geom_histogram(bins = 30, fill = "dodgerblue", color = "black") +
        labs(title = paste("Histogram of Average Differences for", draws, "Draws"),
             x = "Average Difference",
             y = "Frequency") +
        theme_minimal()
    
    print(p)  # Display the plot
}


```








